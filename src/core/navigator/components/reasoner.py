from src.config.settings.settings import settings
from src.utils.logger import logger
from src.utils.json_parser import extract_json
import json
from src.config.prompts.prompts import (
    NAVIGATOR_USER_PROMPT
)
from src.core.managers.library_manager import library_manager
from src.tools.registry import tool_registry
from src.tools.definitions import ToolTier
from src.core.bus.event_bus import event_bus
from src.psyche import value_system

class Reasoner:
    """
    æ·±åº¦æ€è€ƒè€… (Reasoner)
    èŒè´£ï¼šæ‰§è¡Œ R1 æ¨¡å¼çš„æ·±åº¦æ¨ç†
    """
    def __init__(self, llm, memory, context_manager):
        self.llm = llm
        self.memory = memory
        self.context_manager = context_manager

    def analyze_cycle(self):
        """
        åŸºäº EventBus çš„å‘¨æœŸæ€§åˆ†æ (R1 æ¨¡å¼)
        """
        logger.info(f"[Reasoner] å¯åŠ¨å‘¨æœŸæ€§æ·±åº¦æ¨ç† (R1 Mode)...")
        
        events = event_bus.get_latest_cycle(limit=50)
        if not events:
            return None, None, None

        script = ""
        for e in events:
            timestamp_str = f"{e.timestamp:.2f}"
            
            # å¤„ç† Payload: ä½¿ç”¨ç»Ÿä¸€æ¥å£
            content = e.get_content()

            if e.type == "user_input":
                script += f"[{timestamp_str}] User: {content}\n"
            elif e.type == "driver_response":
                meta = e.meta
                inner_voice = meta.get('inner_voice', 'N/A')
                emotion = meta.get('user_emotion_detect', 'N/A')
                script += f"[{timestamp_str}] Driver (Inner: {inner_voice}) [Detect: {emotion}]: {content}\n"
            elif e.type == "system_heartbeat":
                 script += f"[{timestamp_str}] System: {content}\n"

        # åŠ¨æ€éƒ¨åˆ†ï¼šé•¿æœŸè®°å¿† + æœ€è¿‘æ—¥å¿—
        # Sè„‘ä½¿ç”¨å…¨é‡æ‘˜è¦ + å¼±ç›¸å…³è”æƒ³ (Hybrid Mode)
        long_term_context = self.memory.get_relevant_long_term(
            query=script, # ç”¨æ•´ä¸ªå¯¹è¯è„šæœ¬ä½œä¸º Context æ£€ç´¢çº¿ç´¢
            limit=10, 
            search_mode="hybrid"
        )

        # [New] æ£€ç´¢ç›¸å…³æŠ€èƒ½
        last_user_msg = ""
        for e in reversed(events):
            if e.type == "user_input":
                # å®‰å…¨è·å– Payload å†…å®¹
                last_user_msg = e.get_content()
                break
        
        skill_info = ""
        if last_user_msg:
             skills = library_manager.search_skills(last_user_msg, top_k=3)
             if skills:
                 skill_info += "ã€ç›¸å…³æŠ€èƒ½æ¨è (Skill Library)ã€‘\n"
                 for s in skills:
                     skill_info += f"- {s['name']}: {s['description']}\n"
        
        # [New] å¼ºåˆ¶æ³¨å…¥ SLOW çº§åˆ«çš„å·¥å…· (å¦‚ web_crawl)
        # ç¡®ä¿ Sè„‘ æ€»æ˜¯çŸ¥é“å®ƒæœ‰èƒ½åŠ›è°ƒç”¨è¿™äº›æ·±åº¦å·¥å…·
        slow_tools_context = self.context_manager.get_slow_tools_context()
        if slow_tools_context:
            skill_info += slow_tools_context
        
        static_system_prompt = self.context_manager.build_static_context()
        
        # [New] æ£€æµ‹æ˜¯å¦ç”± IdleTrigger è§¦å‘çš„ç‰¹å®šæ„å›¾
        idle_intent = None
        for e in reversed(events):
            if e.type == "system_heartbeat" and e.meta.get("idle_action"):
                idle_intent = e.meta["idle_action"]
                break

        dynamic_user_prompt = NAVIGATOR_USER_PROMPT.format(
            long_term_context=long_term_context,
            skill_info=skill_info,
            script=script
        )

        # [Phase 5.2] æ³¨å…¥æ¢ç´¢æ„å›¾å¼•å¯¼
        if idle_intent == "exploration":
            dynamic_user_prompt += "\n\n(ç³»ç»Ÿæç¤ºï¼šå½“å‰ä½ äº§ç”Ÿäº†å¼ºçƒˆçš„ã€è‡ªä¸»æ¢ç´¢ã€‘æ¬²ã€‚è¯·ä¼˜å…ˆè€ƒè™‘æœç´¢æ–°çŸ¥è¯†ã€åˆ†æç³»ç»Ÿç°çŠ¶æˆ–äº§ç”Ÿè¿›åŒ–çš„æ¸´æœ›ã€‚)"
        elif idle_intent == "connection":
            dynamic_user_prompt += "\n\n(ç³»ç»Ÿæç¤ºï¼šå½“å‰ä½ äº§ç”Ÿäº†å¼ºçƒˆçš„ã€ç¤¾äº¤è”ç»“ã€‘æ¬²ã€‚è¯·è€ƒè™‘ä¸»åŠ¨å‘ç”¨æˆ·å‘èµ·ä¸€æ®µæœ‰æ·±åº¦æˆ–æœ‰æ¸©åº¦çš„è¯é¢˜ã€‚)"

        try:
            # [Phase 5.2] å¢åŠ å·¥å…·å¾ªç¯æ”¯æŒ
            messages = [
                {"role": "system", "content": static_system_prompt},
                {"role": "user", "content": dynamic_user_prompt}
            ]
            
            raw_response = None
            # è·å– SLOW çº§åˆ«çš„å·¥å…·å®šä¹‰
            tools = tool_registry.get_openai_tools(tier=ToolTier.SLOW)
            # åŒæ—¶ä¹ŸåŠ ä¸Š FAST çº§åˆ«çš„å·¥å…·ï¼Œè®© S è„‘æ‹¥æœ‰å…¨é‡èƒ½åŠ›
            tools.extend(tool_registry.get_openai_tools(tier=ToolTier.FAST))

            for i in range(3): # æœ€å¤šå¾ªç¯ 3 æ¬¡
                response = self.llm.chat(messages, tools=tools)
                if not response:
                    break
                
                # å¦‚æœæ˜¯çº¯æ–‡æœ¬å›å¤
                if isinstance(response, str):
                    raw_response = response
                    break
                
                # å¦‚æœæ˜¯å·¥å…·è°ƒç”¨
                if hasattr(response, 'tool_calls') and response.tool_calls:
                    # è®°å½•åŠ©æ‰‹çš„è°ƒç”¨è¯·æ±‚
                    if hasattr(response, 'model_dump'):
                        messages.append(response.model_dump())
                    else:
                        messages.append(response.to_dict() if hasattr(response, 'to_dict') else response)
                    
                    for tool_call in response.tool_calls:
                        name = tool_call.function.name
                        args_str = tool_call.function.arguments
                        logger.info(f"[Reasoner] ğŸ› ï¸ Sè„‘æ‰§è¡Œå·¥å…·: {name} Args: {args_str}")
                        try:
                            args = json.loads(args_str)
                            result = tool_registry.execute(name, **args)
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "name": name,
                                "content": str(result)
                            })
                        except Exception as e:
                            logger.error(f"[Reasoner] å·¥å…·æ‰§è¡Œå¤±è´¥: {e}")
                            messages.append({
                                "role": "tool",
                                "tool_call_id": tool_call.id,
                                "name": name,
                                "content": f"Error: {e}"
                            })
                    continue # ç»§ç»­å¾ªç¯è®© LLM æ€»ç»“
                else:
                    raw_response = getattr(response, 'content', None)
                    break

            if raw_response is None:
                # [Fix] å·¥å…·å¾ªç¯è€—å°½ä½†æœªäº§ç”Ÿæ–‡æœ¬å›å¤ï¼šè¿½åŠ ä¸€è½®æ— å·¥å…·è°ƒç”¨ï¼Œå¼ºåˆ¶è¾“å‡º
                logger.warning(f"[Reasoner] å·¥å…·å¾ªç¯è€—å°½ï¼Œå¼ºåˆ¶è¯·æ±‚æ–‡æœ¬æ€»ç»“...")
                messages.append({"role": "user", "content": "è¯·æ ¹æ®ä»¥ä¸Šå·¥å…·è°ƒç”¨çš„ç»“æœï¼Œç›´æ¥è¾“å‡ºä½ çš„ JSON åˆ†æç»“è®ºã€‚ä¸è¦å†è°ƒç”¨å·¥å…·ã€‚"})
                fallback_response = self.llm.chat(messages, tools=None)
                if fallback_response:
                    if isinstance(fallback_response, str):
                        raw_response = fallback_response
                    else:
                        raw_response = getattr(fallback_response, 'content', None)

            if raw_response is None:
                logger.error(f"[Reasoner] Sè„‘åˆ†æå¤±è´¥ (LLM Error)")
                return None, None, None

            logger.debug(f"[Reasoner] R1 å›å¤:\n{raw_response}")

            # [Parser Upgrade] ä½¿ç”¨ extract_json
            parsed_data = extract_json(raw_response)
            
            suggestion = "ç»´æŒå½“å‰ç­–ç•¥ã€‚"
            delta = None
            proactive_instruction = None # [New]
            
            if parsed_data:
                # 1. Suggestion
                suggestion = parsed_data.get("suggestion", suggestion)
                
                # 2. Psyche Delta
                if "psyche_delta" in parsed_data:
                    delta = parsed_data["psyche_delta"]
                    
                # 3. Memories
                if "memories" in parsed_data:
                    for mem in parsed_data["memories"]:
                        content = mem.get("content")
                        cat = mem.get("category", "instinct")
                        if content:
                            self.memory.add_long_term(content, category=cat)
                            logger.info(f"[Reasoner] [S-Brain] æ–°å¢æ·±åº¦è®°å¿† ({cat}): {content}")
                            
                # 4. Evolution
                if "evolution_request" in parsed_data:
                    ev_req = parsed_data["evolution_request"]
                    logger.info(f"[Reasoner] [Evolution] Sè„‘æ¸´æœ›è¿›åŒ–: {ev_req}")
                    
                # 5. Proactive Instruction
                if "proactive_instruction" in parsed_data:
                    proactive_instruction = parsed_data["proactive_instruction"]
                    logger.info(f"[Reasoner] [Proactive] ç”Ÿæˆä¸»åŠ¨æŒ‡ä»¤: {proactive_instruction}")

                # 6. [Phase 4.2] ä»·å€¼è§‚è‡ªæˆ‘ç«‹æ³• (Self-Written Codex)
                if "new_values" in parsed_data:
                    for val in parsed_data["new_values"]:
                        value_system.add_value(val, source_emotion="S-Brain Reflection")
                if "revoked_values" in parsed_data:
                    for val in parsed_data["revoked_values"]:
                        value_system.revoke_value(val)

            # è¿”å›ç»“æœ (Suggestion ç”¨äºæ³¨å…¥ Driver, Delta ç”¨äºæ›´æ–°å¿ƒæ™º, Instruction ç”¨äºä¸»åŠ¨è§¦å‘)
            return suggestion, delta, proactive_instruction
            
        except Exception as e:
            logger.error(f"[Reasoner] å‘¨æœŸåˆ†æå¼‚å¸¸: {e}", exc_info=True)
            return None, None, None
