from src.config.settings.settings import settings
from src.utils.logger import logger
from src.utils.json_parser import extract_json
from src.config.prompts.prompts import (
    DIARY_GENERATION_PROMPT,
    FACT_EXTRACTION_PROMPT,
    COGNITIVE_GRAPH_PROMPT,
    ALIAS_EXTRACTION_PROMPT,
    AUTONOMOUS_LEARNING_TRIGGER_PROMPT # [New]
)
import time
import concurrent.futures
from src.tools.registry import tool_registry # [New] ç”¨äºç›´æ¥è°ƒç”¨å·¥å…·
from src.memory.services.memory_orchestrator import memory_orchestrator  # [New] å±‚çº§åˆ†ç±»

class Compressor:
    """
    è®°å¿†å‹ç¼©å¸ˆ (Compressor)
    èŒè´£ï¼šæ‰§è¡Œå…·ä½“çš„è®°å¿†å‹ç¼©åŸå­ä»»åŠ¡
    """
    def __init__(self, llm, memory):
        self.llm = llm
        self.memory = memory

    def run_compression_tasks_parallel(self, current_psyche, time_context, script):
        """å¹¶è¡Œæ‰§è¡Œæ‰€æœ‰å‹ç¼©ä»»åŠ¡"""
        logger.info(f"[Compressor] ğŸš€ å¯åŠ¨å¹¶è¡Œè®°å¿†å‹ç¼© (6è·¯å¹¶å‘)...")
        start_time = time.time()
        
        diary_response = None
        
        with concurrent.futures.ThreadPoolExecutor(max_workers=6) as executor:
            # æäº¤ä»»åŠ¡
            future_diary = executor.submit(self.generate_creative_diary, current_psyche, time_context, script)
            future_facts = executor.submit(self.extract_facts, script)
            future_graph = executor.submit(self.build_cognitive_graph, current_psyche, script)
            future_alias = executor.submit(self.extract_aliases, script)
            future_learning = executor.submit(self.trigger_autonomous_learning, script)
            future_classify = executor.submit(self._classify_to_hierarchy, script)  # [New] å±‚çº§åˆ†ç±»
            
            futures = {
                future_diary: "Creative Diary",
                future_facts: "Fact Extraction",
                future_graph: "Cognitive Graph",
                future_alias: "Alias Extraction",
                future_learning: "Autonomous Learning Trigger",
                future_classify: "Hierarchical Classification"  # [New]
            }
            
            for future in concurrent.futures.as_completed(futures):
                name = futures[future]
                try:
                    result = future.result()
                    if future == future_diary:
                        diary_response = result
                    logger.info(f"[Compressor] âœ… {name} å®Œæˆ")
                except Exception as e:
                    logger.error(f"[Compressor] âŒ {name} å¤±è´¥: {e}", exc_info=True)
                    
        logger.info(f"[Compressor] å¹¶è¡Œå‹ç¼©å®Œæˆï¼Œè€—æ—¶: {time.time() - start_time:.2f}s")
        return diary_response
    
    def _classify_to_hierarchy(self, script: str):
        """
        ä»»åŠ¡ 6: å±‚çº§è®°å¿†åˆ†ç±» (Hierarchical Classification)
        å°†å¯¹è¯å½’ç±»åˆ°è¯é¢˜å±‚çº§ç»“æ„
        """
        try:
            result = memory_orchestrator.classify_compressed_memory(script)
            logger.info(f"[Compressor] å±‚çº§åˆ†ç±»ç»“æœ: {result}")
            return result
        except Exception as e:
            logger.warning(f"[Compressor] å±‚çº§åˆ†ç±»å¤±è´¥: {e}")
            return None

    # ... (generate_creative_diary, extract_facts, build_cognitive_graph, extract_aliases ä¿æŒä¸å˜) ...

    def trigger_autonomous_learning(self, script):
        """
        ä»»åŠ¡ 5: è‡ªä¸»å­¦ä¹ è§¦å‘å™¨ (Autonomous Learning)
        åˆ†æå¯¹è¯è®°å½•ï¼Œè¯†åˆ«æœªçŸ¥æ¦‚å¿µï¼Œç›´æ¥è°ƒç”¨ web_search/web_crawl è·å–çŸ¥è¯†ã€‚
        """
        prompt = AUTONOMOUS_LEARNING_TRIGGER_PROMPT.format(script=script)
        
        # ä½¿ç”¨ json mode (å‡è®¾ LLM æ”¯æŒï¼Œæˆ–ä¾é  prompt çº¦æŸ)
        response = self.llm.chat([{"role": "user", "content": prompt}])
        if not response:
            return
            
        try:
            logger.info(f"[Compressor] Autonomous Learning Response: {response}") # [Debug]
            tasks = extract_json(response)
            if not tasks or not isinstance(tasks, list):
                logger.info(f"[Compressor] No learning tasks found or invalid format.")
                return

            for task in tasks:
                query = task.get("query")
                reason = task.get("reason")
                if not query: continue
                
                logger.info(f"[Compressor] ğŸ§  Sè„‘å‘ç°çŸ¥è¯†ç›²åŒº: '{query}' (åŸå› : {reason})")
                
                # ç›´æ¥è°ƒç”¨ web_search å·¥å…· (Sè„‘è‡ªä¸»è¡ŒåŠ¨!)
                # æ³¨æ„ï¼šè¿™é‡Œæˆ‘ä»¬ä½¿ç”¨ web_search è€Œä¸æ˜¯ web_crawlï¼Œå› ä¸º search æ¯”è¾ƒå¿«ä¸”é€šç”¨
                # å¹¶ä¸” web_search (åœ¨æœ¬é¡¹ç›®çš„å®ç°ä¸­) é€šå¸¸ä¼šè¿”å›æ‘˜è¦
                # å¦‚æœéœ€è¦æ·±åº¦å­¦ä¹ ï¼Œå¯ä»¥è°ƒç”¨ web_crawl
                
                # æ£€æŸ¥å·¥å…·æ˜¯å¦å¯ç”¨
                # [Fix] ä½¿ç”¨å…¬å¼€çš„ get_tool() æ–¹æ³•ä»£æ›¿è®¿é—®ç§æœ‰ _tools
                
                try:
                    logger.info(f"[Compressor] ğŸš€ Sè„‘æ­£åœ¨è‡ªä¸»æœç´¢: {query} ...")
                    # ç¡®ä¿ web_search å·¥å…·å·²æ³¨å†Œ
                    if tool_registry.get_tool("web_search") is None:
                         # å°è¯•åŠ¨æ€åŠ è½½ï¼ˆå¦‚æœå°šæœªåŠ è½½ï¼‰
                         from src.tools.builtin import web_tools
                    
                    result = tool_registry.execute("web_search", query=query, max_results=3)
                    
                    # å°†ç»“æœç›´æ¥ä¿å­˜åˆ° Staging åŒº (æ¨¡æ‹Ÿ Crawl çš„æ•ˆæœï¼Œæˆ–è€…åˆ›å»ºä¸“é—¨çš„ Knowledge Note)
                    # ä¸ºäº†å¤ç”¨ KnowledgeIntegratorï¼Œæˆ‘ä»¬å°†ç»“æœä¿å­˜ä¸º .md æ–‡ä»¶
                    self._save_search_result_to_staging(query, result)
                    
                except Exception as e:
                    logger.error(f"[Compressor] Sè„‘è‡ªä¸»æœç´¢å¤±è´¥: {e}", exc_info=True) # [Debug]
                    
        except Exception as e:
            logger.warning(f"[Compressor] è‡ªä¸»å­¦ä¹ è§¦å‘åˆ†æå‡ºé”™: {e}")

    def _save_search_result_to_staging(self, query, content):
        """å°†æœç´¢ç»“æœä¿å­˜åˆ° staging åŒºï¼Œä¾›åç»­ KnowledgeIntegrator å†…åŒ–"""
        import os
        from datetime import datetime
        
        staging_dir = os.path.join(settings.PROJECT_ROOT, "storage", "knowledge_staging")
        os.makedirs(staging_dir, exist_ok=True)
        
        filename = f"s_brain_search_{int(time.time())}.md"
        filepath = os.path.join(staging_dir, filename)
        
        with open(filepath, "w", encoding="utf-8") as f:
            f.write(f"# S-Brain Autonomous Search: {query}\n")
            f.write(f"# Date: {datetime.now().isoformat()}\n\n")
            f.write(str(content))
            
        logger.info(f"[Compressor] âœ… Sè„‘æœç´¢ç»“æœå·²ä¿å­˜è‡³ Staging: {filename}")

    def generate_creative_diary(self, current_psyche, time_context, script):
        """ä»»åŠ¡ 1: ç”Ÿæˆè¶£å‘³æ—¥è®° (Pure Logic)"""
        diary_prompt = DIARY_GENERATION_PROMPT.format(
            current_psyche=current_psyche,
            time_context=time_context,
            script=script
        )

        diary_response = self.llm.chat([{"role": "user", "content": diary_prompt}])
        if diary_response:
            self.memory.write_diary_entry(diary_response)
        return diary_response

    def extract_facts(self, script):
        """ä»»åŠ¡ 2: æå–å·¥ç¨‹è®°å¿† (äº‹å®) - Pure Logic"""
        fact_prompt = FACT_EXTRACTION_PROMPT.format(script=script)
        
        fact_response = self.llm.chat([{"role": "user", "content": fact_prompt}])
        if fact_response and "None" not in fact_response:
            # ç§»é™¤ markdown ä»£ç å—æ ‡è®°
            clean_fact = fact_response.replace("```text", "").replace("```", "").strip()
            lines = clean_fact.split('\n')
            count = 0
            for line in lines:
                line = line.strip().strip('- ')
                if line:
                    self.memory.add_long_term(line, category="fact")
                    count += 1
            # æ³¨æ„ï¼šä¸åœ¨æ­¤å¤„ commitï¼Œç”± Navigator ç»Ÿä¸€ä¿å­˜
            return count
        return 0

    def build_cognitive_graph(self, current_psyche, script):
        """ä»»åŠ¡ 3: æ„å»ºè®¤çŸ¥å›¾è°± - Pure Logic"""
        graph_prompt = COGNITIVE_GRAPH_PROMPT.format(
            current_psyche=current_psyche,
            script=script
        )
        
        graph_response = self.llm.chat([{"role": "user", "content": graph_prompt}])
        if graph_response:
            triplets = extract_json(graph_response)
            
            if isinstance(triplets, list):
                count = 0
                for t in triplets:
                    if all(k in t for k in ["source", "target", "relation"]):
                        meta_data = {
                            "psyche_context": current_psyche,
                            "emotion_tag": t.get("emotion_tag", "neutral")
                        }
                        
                        self.memory.add_triplet(
                            source=t["source"],
                            relation=t["relation"],
                            target=t["target"],
                            weight=t.get("weight", 1.0),
                            relation_type=t.get("relation_type", "general"),
                            meta=meta_data
                        )
                        count += 1
                # ä¸åœ¨æ­¤å¤„ save_graph
                return count
        return 0

    def extract_aliases(self, script):
        """ä»»åŠ¡ 4: æå–å®ä½“åˆ«å - Pure Logic"""
        alias_prompt = ALIAS_EXTRACTION_PROMPT.format(script=script)

        alias_response = self.llm.chat([{"role": "user", "content": alias_prompt}])
        if alias_response:
            aliases = extract_json(alias_response)
            if isinstance(aliases, list):
                count = 0
                for item in aliases:
                    alias = item.get("alias")
                    target = item.get("target")
                    if alias and target:
                        self.memory.save_alias(alias, target)
                        count += 1
                return count
        return 0

    def clean_short_term_memory(self):
        """æ¸…ç†çŸ­æœŸè®°å¿†ï¼Œä¿ç•™æœ€è¿‘ä¸Šä¸‹æ–‡"""
        try:
            # è·å–æœ€è¿‘ 5 æ¡ (ä½¿ç”¨ Facade å±æ€§)
            recent = self.memory.short_term[-5:]
            # æ¸…ç©º (ä½¿ç”¨ Facade æ–¹æ³•)
            self.memory.clear_short_term()
            # åŠ å›æœ€è¿‘ 5 æ¡ (ä½¿ç”¨ Facade æ–¹æ³•ï¼Œä¼šæ­£ç¡®è§¦å‘ WAL)
            for entry in recent:
                self.memory.add_short_term(entry.role, entry.content)
            logger.info(f"[Compressor] çŸ­æœŸè®°å¿†å·²æ¸…ç† (ä¿ç•™ {len(recent)} æ¡ä¸Šä¸‹æ–‡)ã€‚")
        except Exception as e:
            logger.error(f"[Compressor] çŸ­æœŸè®°å¿†æ¸…ç†å¤±è´¥: {e}", exc_info=True)
