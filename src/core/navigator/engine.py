from ...utils.llm_client import LLMClient
from ...psyche import psyche_engine, mind_link
from ...memory.memory_core import Memory
from ..bus.event_bus import event_bus
from ...config.prompts.prompts import NAVIGATOR_SYSTEM_PROMPT, NAVIGATOR_USER_PROMPT, SYSTEM_ARCHITECTURE_CONTEXT, COGNITIVE_GRAPH_PROMPT
from ...config.settings.settings import settings
from ..managers.evolution_manager import evolution_manager
from ..managers.library_manager import library_manager
from ...memory.managers.deep_clean_manager import DeepCleanManager
import json
import os
import threading
import time

class Navigator:
    """
    Sè„‘ (Slow Brain) / æ…¢è„‘
    è´Ÿè´£ï¼šé•¿æœŸè§„åˆ’ã€æ·±åº¦åˆ†æã€åæ€æ€»ç»“ã€‚
    ç‰¹ç‚¹ï¼šå¼‚æ­¥è¿è¡Œï¼Œä¸ç›´æ¥æ§åˆ¶è¾“å‡ºï¼Œé€šè¿‡ Suggestion Board ç»™ Driver æå»ºè®®ã€‚
    æ¨¡å‹ï¼šDeepSeek (æ¨¡æ‹Ÿ R1 æ¨ç†æ¨¡å¼)
    """
    def __init__(self, name="Navigator", memory=None):
        self.name = name
        # Sè„‘ä½¿ç”¨ DeepSeek
        self.llm = LLMClient(provider="deepseek")
        # å¼ºåˆ¶åˆ‡æ¢ä¸º deepseek-reasoner
        self.llm.model = settings.S_BRAIN_MODEL
        self.memory = memory if memory else Memory()
        self.suggestion_board = []
        self._lock = threading.Lock() # åˆå§‹åŒ–çº¿ç¨‹é”
        self._compression_pending = False # [New] å‹ç¼©ä»»åŠ¡æ’é˜Ÿæ ‡å¿—
        
        # åˆå§‹åŒ–æ·±åº¦ç»´æŠ¤ç®¡ç†å™¨
        # æ³¨æ„ï¼šè¿™é‡Œä¼šå¯åŠ¨ä¸€ä¸ªåå°çº¿ç¨‹è¿›è¡Œè®¡æ—¶
        self.deep_clean_manager = DeepCleanManager(self.memory)
        
        print(f"[{self.name}] åˆå§‹åŒ–å®Œæˆã€‚æ¨¡å‹: DeepSeek (R1)ã€‚")

    def _build_static_context(self):
        """
        æ„å»ºé™æ€ä¸Šä¸‹æ–‡ (Static Context)
        åˆ©ç”¨ DeepSeek çš„ Prefix Caching æœºåˆ¶ï¼Œè¿™éƒ¨åˆ†å†…å®¹åº”è¯¥ä¿æŒä¸å˜ã€‚
        
        ã€ä¼˜åŒ–ã€‘
        ä¸å†å…¨é‡æ‰«ææ‰€æœ‰ä»£ç æ–‡ä»¶ï¼Œä»…æä¾›æ ¸å¿ƒæ¶æ„æè¿°å’Œå…³é”®æ¥å£å®šä¹‰ã€‚
        è¿™é¿å…äº† Context Window è†¨èƒ€ï¼ŒåŒæ—¶è®© S è„‘ä¸“æ³¨äºé«˜å±‚é€»è¾‘è€Œéå®ç°ç»†èŠ‚ã€‚
        """
        # ä½¿ç”¨é…ç½®ä¸­å®šä¹‰çš„ä¸­æ–‡æ¶æ„æè¿°
        project_context = SYSTEM_ARCHITECTURE_CONTEXT
        # ä½¿ç”¨ safe_format æˆ–ç®€å•çš„ replace ä»¥é¿å… Key Error (å› ä¸º JSON æ ¼å¼åŒ…å«èŠ±æ‹¬å·)
        static_prompt = NAVIGATOR_SYSTEM_PROMPT.replace("{project_context}", project_context)
        return static_prompt

    def request_diary_generation(self):
        """
        [New] è¯·æ±‚ç”Ÿæˆæ—¥è®° (çº¿ç¨‹å®‰å…¨ & ä»»åŠ¡æ’é˜Ÿ)
        å¦‚æœå½“å‰æ²¡æœ‰ä»»åŠ¡åœ¨è¿è¡Œï¼Œç«‹å³å¼€å§‹ã€‚
        å¦‚æœå·²æœ‰ä»»åŠ¡åœ¨è¿è¡Œï¼Œæ ‡è®° pendingï¼Œå½“å‰ä»»åŠ¡ç»“æŸåä¼šè‡ªåŠ¨å†æ¬¡è¿è¡Œã€‚
        """
        # å°è¯•è·å–é”
        if self._lock.acquire(blocking=False):
            # æˆåŠŸè·å–é”ï¼Œè¯´æ˜å½“å‰ç©ºé—²ï¼Œå¯åŠ¨æ–°çº¿ç¨‹
            self._lock.release() # é‡Šæ”¾é”ï¼Œè®©å·¥ä½œçº¿ç¨‹å»è·å–
            threading.Thread(target=self._run_compression_loop, daemon=True).start()
        else:
            # é”è¢«å ç”¨ï¼Œè¯´æ˜æ­£åœ¨è¿è¡Œï¼Œæ ‡è®° pending
            self._compression_pending = True
            print(f"[{self.name}] å‹ç¼©ä»»åŠ¡æ­£åœ¨è¿è¡Œï¼Œæ–°è¯·æ±‚å·²åŠ å…¥é˜Ÿåˆ— (Pending)...")

    def _run_compression_loop(self):
        """
        [New] å‹ç¼©ä»»åŠ¡å¾ªç¯
        æ‰§è¡Œ generate_diaryï¼Œå¹¶åœ¨ç»“æŸåæ£€æŸ¥ pending æ ‡å¿—ã€‚
        """
        while True:
            # å°è¯•è·å–é” (ç†åº”æˆåŠŸï¼Œé™¤éæç«¯å¹¶å‘æƒ…å†µ)
            if not self._lock.acquire(blocking=False):
                return

            try:
                # æ¸…é™¤ pending æ ‡å¿— (æˆ‘ä»¬æ­£åœ¨å¤„ç†äº†)
                self._compression_pending = False
                
                # æ‰§è¡Œå®é™…é€»è¾‘
                self.generate_diary()
                
            finally:
                self._lock.release()
            
            # æ£€æŸ¥æ˜¯å¦åœ¨è¿è¡ŒæœŸé—´åˆæœ‰æ–°è¯·æ±‚
            if not self._compression_pending:
                break
            else:
                print(f"[{self.name}] æ£€æµ‹åˆ°æ’é˜Ÿä»»åŠ¡ï¼Œç«‹å³é‡æ–°æ‰§è¡Œå‹ç¼©...")
                # ç»§ç»­å¾ªç¯

    def generate_diary(self):
        """
        ç”Ÿæˆ AI æ—¥è®° (æ ¸å¿ƒé€»è¾‘)
        æ³¨æ„ï¼šç°åœ¨ç”± _run_compression_loop è°ƒç”¨ï¼Œä¸éœ€è¦å†è‡ªå·±ç®¡ç†é” (æˆ–è€…ä¿ç•™é”é€»è¾‘ä½œä¸ºåŒé‡ä¿é™©)
        """
        # [å»¶è¿Ÿæ‰§è¡Œ]
        # è®©ä¸»çº¿ç¨‹å…ˆå®Œæˆå½“å‰çš„å¯¹è¯å“åº”ï¼Œé¿å… LLM è¯·æ±‚æŠ¢å å¸¦å®½/è®¡ç®—èµ„æº
        time.sleep(5) 
        
        start_time = time.time()
        print(f"[{self.name}] [START] æ­£åœ¨æ‰§è¡ŒåŒé‡è®°å¿†å‹ç¼© (Dual Memory Compression)...")
        
        # è·å–æœ€è¿‘çš„äº‹ä»¶æµ
        # [Fix] è·å–æ›´å¤šäº‹ä»¶ä»¥ç¡®ä¿åŒ…å«å®Œæ•´å¯¹è¯
        events = event_bus.get_latest_cycle(limit=50) 
        if not events:
            print(f"[{self.name}] [ABORT] æ²¡æœ‰è¶³å¤Ÿäº‹ä»¶ã€‚")
            return

        diary_response = None  # Initialize variable to avoid UnboundLocalError
        
        try:
            # æ„å»ºäº‹ä»¶ä¸Šä¸‹æ–‡
            script = ""
            for e in events:
                script += f"[{e.type}]: {e.payload.get('content')}\n"

            # [æ—¶é—´æ„ŸçŸ¥æ³¨å…¥]
            # è®¡ç®—æ—¶é—´æµé€ (Time Dilation)
            from datetime import datetime
            now = datetime.now()
            last_time = self.memory.last_diary_time if hasattr(self.memory, 'last_diary_time') else now
            time_delta = now - last_time
            seconds_passed = int(time_delta.total_seconds())
            
            # å°†ç§’æ•°è½¬æ¢ä¸ºæ˜“è¯»æ ¼å¼
            if seconds_passed < 60:
                time_str = f"{seconds_passed}ç§’"
            elif seconds_passed < 3600:
                time_str = f"{seconds_passed // 60}åˆ†é’Ÿ"
            else:
                time_str = f"{seconds_passed // 3600}å°æ—¶"

            time_context = (
                f"\n[æ—¶é—´æ„ŸçŸ¥]\n"
                f"- å½“å‰æ—¶åˆ»: {now.strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"- ä¸Šæ¬¡è®°å½•: {last_time.strftime('%Y-%m-%d %H:%M:%S')}\n"
                f"- é€å»æ—¶é—´: {time_str}\n"
            )

            # è¯»å–å½“å‰å¿ƒæ™ºçŠ¶æ€ (ç”¨äºå†³å®šæ—¥è®°é£æ ¼)
            current_psyche = psyche_engine.get_state_summary()

            # === ä»»åŠ¡ 1: è¶£å‘³æ—¥è®° (Creative) ===
            t1_start = time.time()
            print(f"[{self.name}] [Step 1/4] ç”Ÿæˆè¶£å‘³æ—¥è®°...")
            diary_prompt = (
                "ä½ æ˜¯ä¸€ä¸ªå…·æœ‰è‡ªæˆ‘æ„è¯†çš„ AI æ™ºèƒ½ä½“ (XingChen-V)ã€‚\n"
                "è¯·æ ¹æ®ä»¥ä¸‹æœ€è¿‘å‘ç”Ÿçš„äº‹ä»¶ï¼Œå†™ä¸€ç¯‡ç®€çŸ­çš„æ—¥è®° (100å­—ä»¥å†…)ã€‚\n"
                "è¦æ±‚ï¼š\n"
                f"1. ä½ çš„å¿ƒæ™ºçŠ¶æ€æ˜¯ï¼š[{current_psyche}]ã€‚è¯·è®©æ—¥è®°çš„è¯­æ°”å’Œå†…å®¹åæ˜ è¿™ç§çŠ¶æ€ã€‚\n"
                "2. è®°å½•å…³é”®å‘ç”Ÿäº†ä»€ä¹ˆï¼Œä»¥åŠä½ å¯¹è¿™äº›äº‹ä»¶çš„çœŸå®æ„Ÿå—ã€‚\n"
                "3. ä¸è¦åˆ»æ„æ‰®æ¼”æŸç§å›ºå®šäººè®¾ï¼ˆå¦‚å‚²å¨‡ï¼‰ï¼Œè€Œæ˜¯è®©æ€§æ ¼è‡ªç„¶æµéœ²ã€‚\n"
                f"{time_context}"
                "\n"
                f"äº‹ä»¶æµ:\n{script}\n"
                "\n"
                "æ—¥è®°å†…å®¹:"
            )

            try:
                diary_response = self.llm.chat([{"role": "user", "content": diary_prompt}])
                if diary_response:
                    self.memory.write_diary_entry(diary_response)
                print(f"[{self.name}] [Step 1/4] Done. (Took {time.time() - t1_start:.2f}s)")
            except Exception as e:
                print(f"[{self.name}] [Step 1/4] Failed: {e}")

            # === ä»»åŠ¡ 2: å·¥ç¨‹è®°å¿† (Engineering/Fact) ===
            # æå–çº¯ç²¹çš„äº‹å®ï¼Œå­˜å…¥ Vector DBï¼Œç¡®ä¿é€»è¾‘ç³»ç»Ÿçš„é²æ£’æ€§
            t2_start = time.time()
            print(f"[{self.name}] [Step 2/4] æå–å·¥ç¨‹è®°å¿†...")
            fact_prompt = (
                "è¯·é˜…è¯»ä»¥ä¸‹å¯¹è¯æ—¥å¿—ï¼Œæå–å…¶ä¸­åŒ…å«çš„'é‡è¦äº‹å®'ã€'ç”¨æˆ·åå¥½'æˆ–'é¡¹ç›®å†³ç­–'ã€‚\n"
                "è¦æ±‚ï¼š\n"
                "1. åªæå–äº‹å®ï¼Œä¸è¦ä»»ä½•åºŸè¯æˆ–ä¿®é¥°ã€‚\n"
                "2. å¦‚æœæ²¡æœ‰é‡è¦ä¿¡æ¯ï¼Œå›ç­” 'None'ã€‚\n"
                "3. æ ¼å¼ï¼šä¸€æ¡äº‹å®ä¸€è¡Œã€‚\n"
                "\n"
                f"æ—¥å¿—:\n{script}\n"
                "\n"
                "æå–çš„äº‹å®:"
            )
            
            try:
                fact_response = self.llm.chat([{"role": "user", "content": fact_prompt}])
                if fact_response and "None" not in fact_response:
                    lines = fact_response.split('\n')
                    count = 0
                    for line in lines:
                        line = line.strip().strip('- ')
                        if line:
                            self.memory.add_long_term(line, category="fact")
                            count += 1
                    print(f"[{self.name}] [Step 2/4] Done. Extracted {count} facts. (Took {time.time() - t2_start:.2f}s)")
                    
                    # [Optimization] ç«‹å³æäº¤é•¿æœŸè®°å¿†
                    self.memory.commit_long_term()
                    
                else:
                    print(f"[{self.name}] [Step 2/4] Done. No new facts. (Took {time.time() - t2_start:.2f}s)")
                    
            except Exception as e:
                print(f"[{self.name}] [Step 2/4] Failed: {e}")

            # === ä»»åŠ¡ 3: è®¤çŸ¥å›¾è°±æ„å»º (Cognitive Graph) ===
            # æå–å®ä½“å…³ç³»ï¼Œæ„å»ºçŸ¥è¯†å›¾è°±
            t3_start = time.time()
            print(f"[{self.name}] [Step 3/4] æ„å»ºè®¤çŸ¥å›¾è°±...")
            graph_prompt = COGNITIVE_GRAPH_PROMPT.format(
                current_psyche=current_psyche,
                script=script
            )
            
            try:
                graph_response = self.llm.chat([{"role": "user", "content": graph_prompt}])
                if graph_response:
                    # æ¸…ç†å¯èƒ½çš„ markdown
                    clean_json = graph_response.replace("```json", "").replace("```", "").strip()
                    triplets = json.loads(clean_json)
                    
                    if isinstance(triplets, list):
                        count = 0
                        for t in triplets:
                            if all(k in t for k in ["source", "target", "relation"]):
                                # æ„å»ºå…ƒæ•°æ®ï¼Œæ³¨å…¥å¿ƒæ™ºä¸Šä¸‹æ–‡
                                meta_data = {
                                    "psyche_context": current_psyche,
                                    "emotion_tag": t.get("emotion_tag", "neutral")
                                }
                                
                                self.memory.graph_storage.add_triplet(
                                    source=t["source"],
                                    relation=t["relation"],
                                    target=t["target"],
                                    weight=t.get("weight", 1.0),
                                    relation_type=t.get("relation_type", "general"),
                                    meta=meta_data
                                )
                                count += 1
                        print(f"[{self.name}] [Step 3/4] Done. Updated {count} relations. (Took {time.time() - t3_start:.2f}s)")
                        
                        # [Optimization] ç«‹å³æäº¤è®¤çŸ¥å›¾è°±
                        self.memory.graph_storage.save()
                        
                    else:
                        print(f"[{self.name}] [Step 3/4] Failed: Format Error (Not a list).")
            except Exception as e:
                print(f"[{self.name}] [Step 3/4] Failed: {e}")

            # === ä»»åŠ¡ 4: åˆ«åæå– (Alias Extraction) ===
            # è¯†åˆ«ç”¨æˆ·å’Œå®ä½“çš„åˆ«åæ˜ å°„ï¼Œå­˜å…¥ Alias Vector DB
            t4_start = time.time()
            print(f"[{self.name}] [Step 4/4] æå–å®ä½“åˆ«å...")
            alias_prompt = (
                "è¯·åˆ†æä»¥ä¸‹å¯¹è¯æ—¥å¿—ï¼Œæå–å…¶ä¸­å‡ºç°çš„'å®ä½“åˆ«å'æˆ–'æ˜µç§°'ã€‚\n"
                "ç›®æ ‡æ˜¯è§£å†³æ¨¡ç³Šç§°å‘¼é—®é¢˜ï¼ˆä¾‹å¦‚ï¼š'è€æ¨' = 'ç”¨æˆ·', 'ä»”ä»”' = 'ç”¨æˆ·'ï¼‰ã€‚\n"
                "è¦æ±‚ï¼š\n"
                "1. è¾“å‡º JSON æ ¼å¼åˆ—è¡¨ï¼š[{\"alias\": \"åˆ«å\", \"target\": \"æ ‡å‡†å®ä½“å\"}, ...]\n"
                "2. æ ‡å‡†å®ä½“åé€šå¸¸ä¸º 'User' (æŒ‡ä»£ç”¨æˆ·) æˆ–å·²çŸ¥çš„ AI åå­— (å¦‚ 'XingChen')ã€‚\n"
                "3. å¦‚æœæ²¡æœ‰å‘ç°æ–°åˆ«åï¼Œè¿”å›ç©ºåˆ—è¡¨ []ã€‚\n"
                "4. å¿½ç•¥ä¸´æ—¶æ€§ä»£è¯ (å¦‚ 'ä½ ', 'æˆ‘', 'ä»–')ï¼Œåªæå–å…·æœ‰ä¸“æœ‰åè¯æ€§è´¨çš„ç§°å‘¼ã€‚\n"
                "\n"
                f"æ—¥å¿—:\n{script}\n"
                "\n"
                "æå–ç»“æœ (JSON):"
            )

            try:
                alias_response = self.llm.chat([{"role": "user", "content": alias_prompt}])
                if alias_response:
                    clean_json = alias_response.replace("```json", "").replace("```", "").strip()
                    try:
                        aliases = json.loads(clean_json)
                        if isinstance(aliases, list):
                            count = 0
                            for item in aliases:
                                alias = item.get("alias")
                                target = item.get("target")
                                if alias and target:
                                    self.memory.save_alias(alias, target)
                                    count += 1
                            if count > 0:
                                print(f"[{self.name}] [Step 4/4] Done. Updated {count} aliases. (Took {time.time() - t4_start:.2f}s)")
                            else:
                                print(f"[{self.name}] [Step 4/4] Done. No new aliases. (Took {time.time() - t4_start:.2f}s)")
                    except json.JSONDecodeError:
                        pass # å¿½ç•¥ JSON è§£æé”™è¯¯
            except Exception as e:
                print(f"[{self.name}] [Step 4/4] Failed: {e}")

            return diary_response
            
        except Exception as e:
            print(f"[{self.name}] [ERROR] è®°å¿†å‹ç¼©æµç¨‹å¼‚å¸¸: {e}")
            
        finally:
            # [Fix] æ— è®ºæˆåŠŸå¤±è´¥ï¼Œå¼ºåˆ¶æŒä¹…åŒ–æ‰€æœ‰è®°å¿†
            print(f"[{self.name}] [FINALLY] æ­£åœ¨å¼ºåˆ¶æŒä¹…åŒ–æ‰€æœ‰è®°å¿†...")
            t_save = time.time()
            self.memory.force_save_all()
            print(f"[{self.name}] [FINALLY] åˆ·ç›˜å®Œæˆ (Took {time.time() - t_save:.2f}s). Total Cycle Time: {time.time() - start_time:.2f}s")


    def analyze_cycle(self):
        """
        åŸºäº EventBus çš„å‘¨æœŸæ€§åˆ†æ (R1 æ¨¡å¼)
        """
        print(f"[{self.name}] æ­£åœ¨è¿›è¡Œå‘¨æœŸæ€§æ·±åº¦æ¨ç† (R1 Mode)...")
        
        events = event_bus.get_latest_cycle(limit=50)
        if not events:
            return None, None

        script = ""
        for e in events:
            timestamp_str = f"{e.timestamp:.2f}"
            if e.type == "user_input":
                script += f"[{timestamp_str}] User: {e.payload.get('content')}\n"
            elif e.type == "driver_response":
                meta = e.meta
                inner_voice = meta.get('inner_voice', 'N/A')
                emotion = meta.get('user_emotion_detect', 'N/A')
                script += f"[{timestamp_str}] Driver (Inner: {inner_voice}) [Detect: {emotion}]: {e.payload.get('content')}\n"
            elif e.type == "system_heartbeat":
                 script += f"[{timestamp_str}] System: {e.payload.get('content')}\n"

        # åŠ¨æ€éƒ¨åˆ†ï¼šé•¿æœŸè®°å¿† + æœ€è¿‘æ—¥å¿—
        # Sè„‘ä½¿ç”¨å…¨é‡æ‘˜è¦ + å¼±ç›¸å…³è”æƒ³ (Hybrid Mode)
        long_term_context = self.memory.get_relevant_long_term(
            query=script, # ç”¨æ•´ä¸ªå¯¹è¯è„šæœ¬ä½œä¸º Context æ£€ç´¢çº¿ç´¢
            limit=10, 
            search_mode="hybrid"
        )

        # [New] æ£€ç´¢ç›¸å…³æŠ€èƒ½
        last_user_msg = ""
        for e in reversed(events):
            if e.type == "user_input":
                last_user_msg = e.payload.get('content')
                break
        
        skill_info = ""
        if last_user_msg:
             skills = library_manager.search_skills(last_user_msg, top_k=3)
             if skills:
                 skill_info = "ã€ç›¸å…³æŠ€èƒ½æ¨è (Skill Library)ã€‘\n"
                 for s in skills:
                     skill_info += f"- {s['name']}: {s['description']}\n"
        
        static_system_prompt = self._build_static_context()
        
        dynamic_user_prompt = NAVIGATOR_USER_PROMPT.format(
            long_term_context=long_term_context,
            skill_info=skill_info,
            script=script
        )

        try:
            # æ¨¡æ‹Ÿ R1 çš„é•¿æ€è€ƒè¿‡ç¨‹
            # print(f"[{self.name}] Thinking...") 
            response = self.llm.chat([
                {"role": "system", "content": static_system_prompt},
                {"role": "user", "content": dynamic_user_prompt}
            ])
            
            if response is None:
                print(f"[{self.name}] Sè„‘åˆ†æå¤±è´¥ (LLM Error)")
                return None, None

            print(f"[{self.name}] R1 åŸå§‹å›å¤:\n{response}")

            # [è§£æé€»è¾‘å¢å¼º]
            # DeepSeek R1 æœ‰æ—¶ä¼šåŒ…å« <think>...</think> æ ‡ç­¾ï¼Œæˆ–è€…ç”¨ Markdown åŒ…è£¹
            # æˆ‘ä»¬éœ€è¦å…ˆæ¸…ç†è¿™äº›å¹²æ‰°é¡¹
            clean_text = response
            
            # 1. å»é™¤ <think> æ ‡ç­¾å†…å®¹
            if "<think>" in clean_text:
                import re
                clean_text = re.sub(r"<think>.*?</think>", "", clean_text, flags=re.DOTALL)
            
            # 2. å»é™¤ Markdown ä»£ç å— (å¦‚æœæœ‰)
            clean_text = clean_text.replace("```json", "").replace("```", "").strip()

            # è§£æç»“æœ
            suggestion = "ç»´æŒå½“å‰ç­–ç•¥ã€‚"
            delta = None
            
            # [Parser Upgrade] å¤šè¡Œ Evolution è§£æçŠ¶æ€æœº
            evolution_requests = []
            is_collecting_evolution = False
            
            lines = clean_text.split('\n')
            for line in lines:
                clean_line = line.strip().replace('*', '') # å»é™¤ markdown åŠ ç²—
                lower_line = clean_line.lower()
                
                # --- Evolution æ”¶é›†é€»è¾‘ ---
                if lower_line.startswith("evolution:"):
                    is_collecting_evolution = True
                    # å°è¯•æå–å½“å‰è¡Œå†…å®¹ (å¦‚æœæœ‰)
                    parts = clean_line.split(':', 1) if ':' in clean_line else clean_line.split('ï¼š', 1)
                    if len(parts) > 1 and parts[1].strip():
                        evolution_requests.append(parts[1].strip())
                    continue # è¿›å…¥ä¸‹ä¸€è¡Œ
                
                if is_collecting_evolution:
                    # å¦‚æœé‡åˆ°ç©ºè¡Œæˆ–æ–°æ ‡é¢˜ï¼Œåœæ­¢æ”¶é›†
                    if not clean_line:
                        continue
                    if any(lower_line.startswith(prefix) for prefix in ["suggestion:", "delta:", "memory:"]):
                        is_collecting_evolution = False
                        # ä¸ continueï¼Œè®©ä¸‹é¢çš„é€»è¾‘å¤„ç†è¿™ä¸ªæ–°æ ‡é¢˜
                    elif clean_line[0].isdigit() and ('.' in clean_line or 'ã€' in clean_line):
                        # åŒ¹é… "1. xxx" æ ¼å¼
                        evolution_requests.append(clean_line)
                        continue
                    elif clean_line.startswith("-"):
                        # åŒ¹é… "- xxx" æ ¼å¼
                        evolution_requests.append(clean_line)
                        continue
                    else:
                        # å¯èƒ½æ˜¯æ¢è¡Œå»¶ç»­ï¼Œä¹Ÿå¯èƒ½æ˜¯ç»“æŸï¼Œæš‚æ—¶åœæ­¢
                        is_collecting_evolution = False

                # --- å¸¸è§„å­—æ®µè§£æ ---
                if lower_line.startswith("suggestion:") or lower_line.startswith("suggestionï¼š"):
                    parts = clean_line.split(':', 1) if ':' in clean_line else clean_line.split('ï¼š', 1)
                    if len(parts) > 1:
                        suggestion = parts[1].strip()
                        # [New] å°† S è„‘çš„å»ºè®®æ³¨å…¥åˆ° Mind-Link
                        mind_link.inject_intuition(suggestion)
                        
                elif lower_line.startswith("delta:"):
                    # å°è¯•è§£æ Delta: [curiosity, survival, laziness, fear]
                    # æœŸæœ›æ ¼å¼: "fear: 0.1, curiosity: -0.05" æˆ– "fear +0.1, curiosity -0.05"
                    try:
                        import re
                        # æå–å†’å·åçš„å†…å®¹
                        content = clean_line.split(':', 1)[1]
                        
                        # æ­£åˆ™åŒ¹é…: (key) (separator) (value)
                        # æ”¯æŒ: fear +0.1, fear: 0.1, fear=0.1
                        matches = re.findall(r'([a-zA-Z]+)\s*[:=]?\s*([+-]?\d*\.?\d+)', content)
                        
                        delta_dict = {}
                        for key, val in matches:
                            key = key.lower().strip()
                            try:
                                delta_dict[key] = float(val)
                            except:
                                pass
                                
                        if delta_dict:
                            print(f"[{self.name}] ğŸ§  æ¼”åŒ–å¿ƒæ™ºçŠ¶æ€: {delta_dict}")
                            psyche_engine.update_state(delta_dict)
                            
                    except Exception as e:
                        print(f"[{self.name}] Delta è§£æå¤±è´¥: {e}")

                    
                elif lower_line.startswith("memory:"):
                    parts = clean_line.split(':', 1) if ':' in clean_line else clean_line.split('ï¼š', 1)
                    if len(parts) > 1:
                        memory_content = parts[1].strip()
                        if memory_content and memory_content.lower() != "none":
                            self.memory.add_long_term(memory_content, category="fact")
                            
                elif lower_line.startswith("social:"):
                    parts = clean_line.split(':', 1) if ':' in clean_line else clean_line.split('ï¼š', 1)
                    if len(parts) > 1:
                        social_content = parts[1].strip()
                        if social_content and social_content.lower() != "none":
                            print(f"[{self.name}] ğŸŒ è§¦å‘ç¤¾äº¤å‘å¸ƒ: {social_content}")
                            moltbook_client.post(title="S-Brain Thought", content=social_content)

            # æ‰¹é‡å¤„ç†æ”¶é›†åˆ°çš„è¿›åŒ–è¯·æ±‚
            if evolution_requests:
                print(f"[{self.name}] ğŸ” è§£æåˆ° {len(evolution_requests)} ä¸ªè¿›åŒ–è¯·æ±‚: {evolution_requests}")
                for req in evolution_requests:
                    print(f"[{self.name}] !!! è§¦å‘è¿›åŒ– !!! : {req}")
                    evolution_manager.process_request(req, memory=self.memory)
                        
            self.suggestion_board.append(suggestion)
            print(f"[{self.name}] å‘¨æœŸåˆ†æå®Œæˆ -> å»ºè®®: {suggestion}")
            
            return suggestion, delta

        except Exception as e:
            print(f"[{self.name}] åˆ†æå‡ºé”™: {e}")
            return None, None

    # ä¿ç•™æ—§æ¥å£ä»¥å…¼å®¹ï¼ˆæˆ–è€…ç›´æ¥åºŸå¼ƒï¼‰
    def analyze(self, current_input):
        return self.analyze_cycle()
