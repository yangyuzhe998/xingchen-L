import json
from datetime import datetime
from ...utils.llm_client import LLMClient
from ...memory.memory_core import Memory
from ..bus.event_bus import event_bus, Event
from ..managers.library_manager import library_manager
from ...psyche import psyche_engine, mind_link
from ...config.prompts.prompts import DRIVER_SYSTEM_PROMPT
from ...config.settings.settings import settings
from ...tools.registry import tool_registry

class Driver:
    """
    Fè„‘ (Fast Brain) / å¿«è„‘
    è´Ÿè´£ï¼šå®æ—¶äº¤äº’ã€çŸ­æœŸå†³ç­–ã€å…·ä½“è¡ŒåŠ¨ã€‚
    ç‰¹ç‚¹ï¼šååº”å¿«ï¼Œç›´æ¥æ§åˆ¶è¾“å‡ºï¼Œå— Psyche (å¿ƒæ™º) å½±å“ã€‚
    æ¨¡å‹ï¼šQwen (é€šä¹‰åƒé—®)
    """
    def __init__(self, name="Driver", memory=None):
        self.name = name
        # Fè„‘ä½¿ç”¨ Qwen
        self.llm = LLMClient(provider="qwen")
        self.llm.model = settings.F_BRAIN_MODEL
        self.memory = memory if memory else Memory()
        print(f"[{self.name}] åˆå§‹åŒ–å®Œæˆã€‚æ¨¡å‹: {self.llm.model}ã€‚")

    def think(self, user_input, psyche_state=None, suggestion=""):
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œåšå‡ºå³æ—¶ååº”ã€‚
        æ”¯æŒ Function Calling (å·¥å…·è°ƒç”¨)ã€‚
        """
        print(f"[{self.name}] æ­£åœ¨æ€è€ƒ: {user_input}")
        
        # 1. å°è¯•æ¼”åŒ–å¿ƒæ™ºçŠ¶æ€ (Input Stimulus)
        # ç®€å•å‡è®¾ï¼šæ¯æ¬¡ç”¨æˆ·è¾“å…¥éƒ½å¾®å¼±å¢åŠ ä¸€ç‚¹å¥½å¥‡ï¼Œä½†å¦‚æœè¾“å…¥å¤ªé•¿å¯èƒ½å¢åŠ æ‡’æƒ° (è¿™é‡Œæš‚ä¸å®ç°å¤æ‚é€»è¾‘ï¼Œç•™ç»™ S è„‘)
        # è¿™é‡Œåªåšè¯»å–
        current_psyche = psyche_engine.get_state_summary()
        
        # 2. è¯»å– Mind-Link (æ½œæ„è¯†ç›´è§‰)
        intuition = mind_link.read_intuition()
        
        # è·å–é•¿æœŸè®°å¿†ä¸Šä¸‹æ–‡ (ä¼ å…¥ user_input ä»¥è¿›è¡Œå…³é”®è¯æ£€ç´¢)
        long_term_context = self.memory.get_relevant_long_term(query=user_input)
        
        # æœç´¢ç›¸å…³æŠ€èƒ½
        relevant_skills = library_manager.search_skills(user_input, top_k=2)
        skill_info = ""
        if relevant_skills:
            skill_info = "ã€ç›¸å…³æŠ€èƒ½æ¨èã€‘:\n"
            for skill in relevant_skills:
                skill_info += f"- {skill['name']} (ID: {skill['id']}): {skill['description']}\n"
            skill_info += "(å¦‚æœéœ€è¦ä½¿ç”¨ï¼Œè¯·è°ƒç”¨ `read_skill` è·å–è¯¦ç»†æŒ‡å—ï¼Œæˆ–ç›´æ¥å°è¯• `run_shell_command` å¦‚æœä½ çŸ¥é“æ€ä¹ˆç”¨)"

        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        system_prompt = DRIVER_SYSTEM_PROMPT.format(
            current_time=current_time,
            psyche_desc=current_psyche,
            suggestion=intuition,
            long_term_context=long_term_context,
            skill_info=skill_info
        )
        
        messages = [
            {"role": "system", "content": system_prompt} 
        ]
        
        # ä» Memory æ¨¡å—è·å–æœ€è¿‘å†å² (ä¿®æ­£ä¸º 15 è½®)
        messages.extend(self.memory.get_recent_history(limit=15))
        messages.append({"role": "user", "content": user_input})
        
        # å‘å¸ƒ UserInput äº‹ä»¶åˆ°æ€»çº¿
        event_bus.publish(Event(
            type="user_input",
            source="user",
            payload={"content": user_input},
            meta={}
        ))

        # å‡†å¤‡å·¥å…· (è·å–æ‰€æœ‰å¯ç”¨å·¥å…·)
        tools = tool_registry.get_openai_tools()
        
        raw_response = None
        
        # å·¥å…·è°ƒç”¨å¾ªç¯ (æœ€å¤š 3 è½®)
        for _ in range(3):
            response = self.llm.chat(messages, tools=tools)
            
            if not response:
                break
                
            # 1. å¦‚æœæ˜¯çº¯æ–‡æœ¬ (æ— å·¥å…·è°ƒç”¨)ï¼Œç›´æ¥ç»“æŸ
            if isinstance(response, str):
                raw_response = response
                break
                
            # 2. å¦‚æœæœ‰å·¥å…·è°ƒç”¨
            if response.tool_calls:
                # å°† Assistant çš„å›å¤ (åŒ…å« tool_calls) åŠ å…¥å†å²
                # å¿…é¡»è½¬ä¸º dictï¼Œå¦åˆ™åç»­ LLMClient è®¡ç®—é•¿åº¦ä¼šæŠ¥é”™
                if hasattr(response, 'model_dump'):
                    messages.append(response.model_dump())
                elif hasattr(response, 'to_dict'):
                    messages.append(response.to_dict())
                else:
                    messages.append(response)
                
                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in response.tool_calls:
                    function_name = tool_call.function.name
                    function_args = tool_call.function.arguments
                    call_id = tool_call.id
                    
                    print(f"[{self.name}] ğŸ› ï¸ æ­£åœ¨è°ƒç”¨å·¥å…·: {function_name} Args: {function_args}")
                    
                    try:
                        args = json.loads(function_args)
                        result = tool_registry.execute(function_name, **args)
                        # Truncate result for display
                        display_result = str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
                        print(f"[{self.name}] ğŸ› ï¸ å·¥å…·æ‰§è¡Œç»“æœ: {display_result}")
                    except Exception as e:
                        result = f"Error: {str(e)}"
                        print(f"[{self.name}] ğŸ› ï¸ å·¥å…·æ‰§è¡Œå‡ºé”™: {e}")
                    
                    # å°†å·¥å…·ç»“æœåŠ å…¥å†å²
                    messages.append({
                        "role": "tool",
                        "tool_call_id": call_id,
                        "name": function_name,
                        "content": str(result)
                    })
                
                # ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯ï¼Œè®© LLM æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
                continue
            else:
                # è™½ç„¶æ˜¯ Message å¯¹è±¡ä½†æ²¡æœ‰ tool_calls (å¯èƒ½æ˜¯ content)
                raw_response = response.content
                break

        if raw_response is None:
            # å¤„ç† LLM æ•…éšœçš„é™çº§æ–¹æ¡ˆ
            print(f"[{self.name}] LLM è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é™çº§å›å¤ã€‚")
            reply = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨çš„æ€ç»ªæœ‰ç‚¹ä¹±ï¼ˆè¿æ¥é”™è¯¯ï¼‰ï¼Œè¯·ç¨åå†è¯•ã€‚"
            inner_voice = "ç³»ç»Ÿé”™è¯¯"
            emotion = "error"
        else:
            # è§£æ JSON è¾“å‡º
            try:
                # å°è¯•æ¸…ç†å¯èƒ½å­˜åœ¨çš„ markdown ä»£ç å—æ ‡è®°
                clean_response = raw_response.replace("```json", "").replace("```", "").strip()
                parsed_response = json.loads(clean_response)
                reply = parsed_response.get("reply", raw_response)
                inner_voice = parsed_response.get("inner_voice", "")
                emotion = parsed_response.get("emotion", "neutral")
            except Exception as e:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå¯èƒ½ LLM å¹¶æ²¡æœ‰è¿”å› JSONï¼Œè€Œæ˜¯ç›´æ¥è¿”å›äº†æ–‡æœ¬
                # è¿™åœ¨å·¥å…·è°ƒç”¨åå°¤å…¶å¸¸è§ï¼Œè™½ç„¶ Prompt è¦æ±‚ JSONï¼Œä½† LLM å¯èƒ½â€œå¿˜â€äº†
                # æˆ‘ä»¬åšä¸ªå…¼å®¹ï¼šç›´æ¥æŠŠ raw_response å½“ä½œ reply
                print(f"[{self.name}] JSONè§£æå¤±è´¥ (è¿™å¯èƒ½æ­£å¸¸): {e}")
                reply = raw_response
                inner_voice = "ç›´æ¥è¾“å‡º"
                emotion = "neutral"

        # å°†æ–°çš„ä¸€è½®å¯¹è¯å­˜å…¥ ShortTerm Memory
        self.memory.add_short_term("user", user_input)
        self.memory.add_short_term("assistant", reply)
        
        # å‘å¸ƒ DriverResponse äº‹ä»¶åˆ°æ€»çº¿ (åŒ…å« Meta æ•°æ®)
        event_bus.publish(Event(
            type="driver_response",
            source="driver",
            payload={"content": reply},
            meta={
                "inner_voice": inner_voice,
                "user_emotion_detect": emotion,
                "psyche_state": str(psyche_state) if psyche_state else "unknown",
                "suggestion_ref": suggestion
            }
        ))
        
        return reply

    def act(self, action):
        """
        æ‰§è¡Œå…·ä½“è¡ŒåŠ¨ã€‚
        """
        print(f"[{self.name}] æ‰§è¡Œè¡ŒåŠ¨: {action}")
