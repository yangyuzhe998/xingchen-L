import json
import threading
import time
from datetime import datetime
from ...utils.llm_client import LLMClient
from ...utils.logger import logger
from ...utils.json_parser import extract_json
from ...memory.memory_core import Memory
from ..bus.event_bus import event_bus, Event
from ..managers.library_manager import library_manager
from ...psyche import psyche_engine, mind_link
from ...config.prompts.prompts import DRIVER_SYSTEM_PROMPT, PROACTIVE_DRIVER_PROMPT
from ...config.settings.settings import settings
from ...tools.registry import tool_registry

class Driver:
    """
    Fè„‘ (Fast Brain) / å¿«è„‘
    è´Ÿè´£ï¼šå®æ—¶äº¤äº’ã€çŸ­æœŸå†³ç­–ã€å…·ä½“è¡ŒåŠ¨ã€‚
    ç‰¹ç‚¹ï¼šååº”å¿«ï¼Œç›´æ¥æ§åˆ¶è¾“å‡ºï¼Œå— Psyche (å¿ƒæ™º) å½±å“ã€‚
    æ¨¡å‹ï¼šQwen (é€šä¹‰åƒé—®)
    """
    def __init__(self, name="Driver", memory=None):
        self.name = name
        # Fè„‘ä½¿ç”¨ Qwen
        self.llm = LLMClient(provider="qwen")
        self.llm.model = settings.F_BRAIN_MODEL
        self.memory = memory if memory else Memory()
        
        # è®¢é˜…äº‹ä»¶æ€»çº¿
        event_bus.subscribe(self._on_event)
        self._thinking_lock = threading.Lock() # é˜²æ­¢æ€è€ƒå†²çª
        self.last_interaction_time = 0 # ä¸Šæ¬¡äº’åŠ¨æ—¶é—´ (Unix Timestamp)
        
        logger.info(f"[{self.name}] åˆå§‹åŒ–å®Œæˆã€‚æ¨¡å‹: {self.llm.model}ã€‚")

    def _on_event(self, event):
        """äº‹ä»¶ç›‘å¬"""
        if event.type == "proactive_instruction":
            instruction = event.payload.get("content")
            if instruction:
                # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶æ€»çº¿åˆ†å‘
                threading.Thread(target=self.proactive_speak, args=(instruction,), daemon=True).start()

    def proactive_speak(self, instruction):
        """
        [New] ä¸»åŠ¨å‘èµ·å¯¹è¯ (åŸºäº Sè„‘ æŒ‡ä»¤)
        """
        # 1. å†·å´æ£€æŸ¥
        if time.time() - self.last_interaction_time < settings.PROACTIVE_COOLDOWN:
            logger.info(f"[{self.name}] å¤„äºå†·å´æœŸï¼Œè·³è¿‡ä¸»åŠ¨å‘è¨€æŒ‡ä»¤: {instruction[:20]}...")
            return

        # å¦‚æœæ­£åœ¨æ€è€ƒï¼ˆå¤„ç†ç”¨æˆ·è¾“å…¥ï¼‰ï¼Œåˆ™å¿½ç•¥è¿™æ¬¡ä¸»åŠ¨å°è¯•
        if not self._thinking_lock.acquire(blocking=False):
            logger.info(f"[{self.name}] æ­£åœ¨å¿™äºå›å¤ç”¨æˆ·ï¼Œå¿½ç•¥ä¸»åŠ¨å¹²é¢„æŒ‡ä»¤: {instruction}")
            return

        try:
            print(f"\n[{self.name}] âš¡ æ”¶åˆ°æ½œæ„è¯†å†²åŠ¨: {instruction}")
            
            # [Fix] ç¡®ä¿ instruction æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ˜¯å­—å…¸åˆ™è½¬ä¸º JSON å­—ç¬¦ä¸²
            instruction_str = json.dumps(instruction, ensure_ascii=False) if isinstance(instruction, (dict, list)) else str(instruction)
            
            current_psyche = psyche_engine.get_state_summary()
            # ä½¿ç”¨è½¬æ¢åçš„å­—ç¬¦ä¸²è¿›è¡Œæ£€ç´¢
            long_term_context = self.memory.get_relevant_long_term(query=instruction_str, limit=5)
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            system_prompt = PROACTIVE_DRIVER_PROMPT.format(
                current_time=current_time,
                psyche_desc=current_psyche,
                instruction=instruction_str, # ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼
                long_term_context=long_term_context
            )

            # è°ƒç”¨ LLM ç”Ÿæˆä¸»åŠ¨è¯è¯­
            # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦ toolsï¼Œå› ä¸ºåªæ˜¯å•çº¯çš„å¼€å¯è¯é¢˜
            response = self.llm.chat([{"role": "system", "content": system_prompt}])
            
            if response:
                try:
                    parsed = extract_json(response)
                    reply = parsed.get("reply", response) if parsed else response
                    inner_voice = parsed.get("inner_voice", "æˆ‘æƒ³è¯´è¯...") if parsed else ""
                    emotion = parsed.get("emotion", "curious") if parsed else "neutral"
                except:
                    reply = response
                    inner_voice = ""
                    emotion = "neutral"

                # è¾“å‡ºç»“æœ
                # æ³¨æ„ï¼šåœ¨ CLI æ¨¡å¼ä¸‹ï¼Œè¿™å¯èƒ½ä¼šæ‰“æ–­ç”¨æˆ·çš„è¾“å…¥è¡Œï¼Œè¿™æ˜¯å·²çŸ¥é™åˆ¶
                print(f"\n[{self.name}] (ä¸»åŠ¨): {reply}")
                
                # å­˜å…¥çŸ­æœŸè®°å¿†
                self.memory.add_short_term("assistant", reply)
                
                # å‘å¸ƒäº‹ä»¶
                event_bus.publish(Event(
                    type="driver_response",
                    source="driver",
                    payload={"content": reply},
                    meta={
                        "inner_voice": inner_voice,
                        "user_emotion_detect": emotion,
                        "proactive": True
                    }
                ))
        except Exception as e:
            logger.error(f"[{self.name}] ä¸»åŠ¨å‘è¨€å¤±è´¥: {e}", exc_info=True)
        finally:
            self._thinking_lock.release()

    def think(self, user_input, psyche_state=None, suggestion=""):
        """
        å¤„ç†ç”¨æˆ·è¾“å…¥ï¼Œåšå‡ºå³æ—¶ååº”ã€‚
        æ”¯æŒ Function Calling (å·¥å…·è°ƒç”¨)ã€‚
        """
        # è·å–é”ï¼Œæ ‡å¿—æ­£åœ¨æ€è€ƒ
        # æ³¨æ„ï¼šè¿™ä¼šé˜»å¡ç›´åˆ°è·å¾—é”ï¼Œç¡®ä¿ä¸ä¼šä¸ proactive_speak å†²çª
        with self._thinking_lock:
            response = self._think_internal(user_input, psyche_state, suggestion)
            
            # æ›´æ–°æœ€åäº’åŠ¨æ—¶é—´
            self.last_interaction_time = time.time()
            
            return response

    def _think_internal(self, user_input, psyche_state=None, suggestion=""):
        print(f"[{self.name}] æ­£åœ¨æ€è€ƒ: {user_input}")
        
        # 1. å°è¯•æ¼”åŒ–å¿ƒæ™ºçŠ¶æ€ (Input Stimulus)
        # ç®€å•å‡è®¾ï¼šæ¯æ¬¡ç”¨æˆ·è¾“å…¥éƒ½å¾®å¼±å¢åŠ ä¸€ç‚¹å¥½å¥‡ï¼Œä½†å¦‚æœè¾“å…¥å¤ªé•¿å¯èƒ½å¢åŠ æ‡’æƒ° (è¿™é‡Œæš‚ä¸å®ç°å¤æ‚é€»è¾‘ï¼Œç•™ç»™ S è„‘)
        # [New] æ ¹æ®è¾“å…¥é•¿åº¦å’Œå†…å®¹ç®€å•è°ƒæ•´äº²å¯†åº¦ (æ¨¡æ‹Ÿ)
        # åœ¨çœŸå®åœºæ™¯ä¸­ï¼Œè¿™åº”è¯¥ç”± S è„‘æ ¹æ®æƒ…æ„Ÿåˆ†ææ¥é©±åŠ¨
        # è¿™é‡Œåšä¸€ä¸ªç®€å•çš„ Hack: æ¯æ¬¡äº’åŠ¨å¾®å¼±å¢åŠ äº²å¯†åº¦
        psyche_engine.update_state({"intimacy": 0.01})

        # è¿™é‡Œåªåšè¯»å–
        current_psyche = psyche_engine.get_state_summary()
        
        # 2. è¯»å– Mind-Link (æ½œæ„è¯†ç›´è§‰)
        # [Fix] å¢åŠ é‡è¯•/ç­‰å¾…æœºåˆ¶ï¼Ÿæš‚æ—¶ä¿æŒç›´æ¥è¯»å–ï¼Œä½†å¢åŠ  Log
        intuition = mind_link.read_intuition()
        if intuition:
             logger.info(f"[{self.name}] ğŸ§  æ„ŸçŸ¥åˆ°æ½œæ„è¯†ç›´è§‰: {intuition[:30]}...")
        
        # è·å–é•¿æœŸè®°å¿†ä¸Šä¸‹æ–‡ (ä¼ å…¥ user_input ä»¥è¿›è¡Œå…³é”®è¯æ£€ç´¢)
        long_term_context = self.memory.get_relevant_long_term(query=user_input)
        
        # [New] æ¨¡ç³Šåˆ«åè§£æ (Fuzzy Alias Resolution)
        # å°è¯•ä»ç”¨æˆ·è¾“å…¥ä¸­æ£€ç´¢æ˜¯å¦åŒ…å«å·²çŸ¥çš„åˆ«å
        try:
            alias_match = self.memory.search_alias(query=user_input, threshold=0.4)
            if alias_match:
                alias, target, dist = alias_match
                print(f"[{self.name}] ğŸ” æ£€æµ‹åˆ°æ¨¡ç³Šåˆ«å: '{alias}' -> '{target}' (dist: {dist:.4f})")
                # æ³¨å…¥åˆ«åè§£é‡Šåˆ° Context
                alias_context = f"\n[System Note]: ç”¨æˆ·å½“å‰æåˆ°çš„ '{alias}' åœ¨ç³»ç»Ÿä¸­è¢«è¯†åˆ«ä¸º '{target}'ã€‚\n"
                # å¦‚æœæ˜¯â€œç”¨æˆ·â€æœ¬èº«ï¼Œè¿˜å¯ä»¥é¡ºä¾¿åŠ è½½ç”¨æˆ·çš„ Profile
                if target == "User" or target == "ç”¨æˆ·":
                    alias_context += "(å·²è‡ªåŠ¨å…³è”ç”¨æˆ·ç”»åƒ)\n"
                
                # å°†å…¶æ‹¼æ¥åˆ° long_term_context æœ€å‰æ–¹
                long_term_context = alias_context + long_term_context
        except Exception as e:
            print(f"[{self.name}] åˆ«åæ£€ç´¢å¼‚å¸¸: {e}")
        
        # [New] å°è¯•æ£€ç´¢å›¾è°±ä¸­çš„ç”¨æˆ·ç”»åƒ (Graph Profile)
        # ç®€å•æ£€ç´¢ï¼šç›´æ¥æŸ¥æ‰¾ "ç”¨æˆ·" ç›¸å…³çš„å±æ€§å’Œç¤¾äº¤å…³ç³»
        try:
            user_profile = self.memory.graph_storage.get_cognitive_subgraph("ç”¨æˆ·", relation_type="attribute")
            user_profile += self.memory.graph_storage.get_cognitive_subgraph("ç”¨æˆ·", relation_type="social")
            if user_profile:
                profile_str = "\nã€ç”¨æˆ·ç”»åƒ (Graph Memory)ã€‘:\n"
                for p in user_profile:
                    # æ ¼å¼åŒ–: ç”¨æˆ· --[relation]--> target (meta)
                    profile_str += f"- ç”¨æˆ· {p['relation']} {p['target']}"
                    if p.get('meta') and p['meta'].get('emotion_tag'):
                         profile_str += f" (Emotion: {p['meta']['emotion_tag']})"
                    profile_str += "\n"
                long_term_context += profile_str
        except Exception as e:
            logger.warning(f"[{self.name}] å›¾è°±ç”»åƒæ£€ç´¢å¤±è´¥: {e}")
            
        # æœç´¢ç›¸å…³æŠ€èƒ½
        relevant_skills = library_manager.search_skills(user_input, top_k=2)
        skill_info = ""
        if relevant_skills:
            skill_info = "ã€ç›¸å…³æŠ€èƒ½æ¨èã€‘:\n"
            for skill in relevant_skills:
                skill_info += f"- {skill['name']} (ID: {skill['id']}): {skill['description']}\n"
            skill_info += "(å¦‚æœéœ€è¦ä½¿ç”¨ï¼Œè¯·è°ƒç”¨ `read_skill` è·å–è¯¦ç»†æŒ‡å—ï¼Œæˆ–ç›´æ¥å°è¯• `run_shell_command` å¦‚æœä½ çŸ¥é“æ€ä¹ˆç”¨)"

        current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

        system_prompt = DRIVER_SYSTEM_PROMPT.format(
            current_time=current_time,
            psyche_desc=current_psyche,
            suggestion=intuition,
            long_term_context=long_term_context,
            skill_info=skill_info
        )
        
        messages = [
            {"role": "system", "content": system_prompt} 
        ]
        
        # ä» Memory æ¨¡å—è·å–æœ€è¿‘å†å² (ä¿®æ­£ä¸º 15 è½®)
        messages.extend(self.memory.get_recent_history(limit=15))
        messages.append({"role": "user", "content": user_input})
        
        # å‘å¸ƒ UserInput äº‹ä»¶åˆ°æ€»çº¿
        event_bus.publish(Event(
            type="user_input",
            source="user",
            payload={"content": user_input},
            meta={}
        ))

        # å‡†å¤‡å·¥å…· (è·å–æ‰€æœ‰å¯ç”¨å·¥å…·)
        tools = tool_registry.get_openai_tools()
        
        raw_response = None
        
        # å·¥å…·è°ƒç”¨å¾ªç¯ (æœ€å¤š 3 è½®)
        for _ in range(3):
            response = self.llm.chat(messages, tools=tools)
            
            if not response:
                break
                
            # 1. å¦‚æœæ˜¯çº¯æ–‡æœ¬ (æ— å·¥å…·è°ƒç”¨)ï¼Œç›´æ¥ç»“æŸ
            if isinstance(response, str):
                raw_response = response
                break
                
            # 2. å¦‚æœæœ‰å·¥å…·è°ƒç”¨
            if response.tool_calls:
                # å°† Assistant çš„å›å¤ (åŒ…å« tool_calls) åŠ å…¥å†å²
                # å¿…é¡»è½¬ä¸º dictï¼Œå¦åˆ™åç»­ LLMClient è®¡ç®—é•¿åº¦ä¼šæŠ¥é”™
                if hasattr(response, 'model_dump'):
                    messages.append(response.model_dump())
                elif hasattr(response, 'to_dict'):
                    messages.append(response.to_dict())
                else:
                    messages.append(response)
                
                # æ‰§è¡Œæ‰€æœ‰å·¥å…·è°ƒç”¨
                for tool_call in response.tool_calls:
                    function_name = tool_call.function.name
                    function_args = tool_call.function.arguments
                    call_id = tool_call.id
                    
                    print(f"[{self.name}] ğŸ› ï¸ æ­£åœ¨è°ƒç”¨å·¥å…·: {function_name} Args: {function_args}")
                    
                    try:
                        args = json.loads(function_args)
                        result = tool_registry.execute(function_name, **args)
                        # Truncate result for display
                        display_result = str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
                        print(f"[{self.name}] ğŸ› ï¸ å·¥å…·æ‰§è¡Œç»“æœ: {display_result}")
                    except Exception as e:
                        result = f"Error: {str(e)}"
                        print(f"[{self.name}] ğŸ› ï¸ å·¥å…·æ‰§è¡Œå‡ºé”™: {e}")
                    
                    # å°†å·¥å…·ç»“æœåŠ å…¥å†å²
                    messages.append({
                        "role": "tool",
                        "tool_call_id": call_id,
                        "name": function_name,
                        "content": str(result)
                    })
                
                # ç»§ç»­ä¸‹ä¸€è½®å¾ªç¯ï¼Œè®© LLM æ ¹æ®å·¥å…·ç»“æœç”Ÿæˆæœ€ç»ˆå›å¤
                continue
            else:
                # è™½ç„¶æ˜¯ Message å¯¹è±¡ä½†æ²¡æœ‰ tool_calls (å¯èƒ½æ˜¯ content)
                raw_response = response.content
                break
        
        # [New] æ‰‹åŠ¨è§¦å‘æ·±åº¦ç»´æŠ¤ (Deep Clean)
        if "æ·±åº¦ç»´æŠ¤" in user_input or "/deep_clean" in user_input:
            logger.info(f"[{self.name}] æ”¶åˆ°æ·±åº¦ç»´æŠ¤æŒ‡ä»¤ï¼Œæ­£åœ¨è½¬å‘ç»™ S è„‘...")
            if hasattr(self.memory, 'navigator') and self.memory.navigator:
                 # å¼‚æ­¥è§¦å‘ï¼Œä¸é˜»å¡å½“å‰å¯¹è¯
                 threading.Thread(target=self.memory.navigator.deep_clean_manager.perform_deep_clean, args=("manual",), daemon=True).start()
                 reply = "å¥½çš„ï¼Œæ­£åœ¨å¯åŠ¨æ·±åº¦ç»´æŠ¤ç¨‹åºã€‚è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·ç¨å€™..."
                 inner_voice = "ç³»ç»Ÿç»´æŠ¤"
                 emotion = "serious"
                 # ç›´æ¥è¿”å›ï¼Œè·³è¿‡ LLM è§£æ
                 self.memory.add_short_term("user", user_input)
                 self.memory.add_short_term("assistant", reply)
                 event_bus.publish(Event(type="driver_response", source="driver", payload={"content": reply}, meta={"inner_voice": inner_voice}))
                 return reply

        if raw_response is None:
            # å¤„ç† LLM æ•…éšœçš„é™çº§æ–¹æ¡ˆ
            print(f"[{self.name}] LLM è°ƒç”¨å¤±è´¥ï¼Œä½¿ç”¨é™çº§å›å¤ã€‚")
            reply = "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨çš„æ€ç»ªæœ‰ç‚¹ä¹±ï¼ˆè¿æ¥é”™è¯¯ï¼‰ï¼Œè¯·ç¨åå†è¯•ã€‚"
            inner_voice = "ç³»ç»Ÿé”™è¯¯"
            emotion = "error"
        else:
            # è§£æ JSON è¾“å‡º
            try:
                # ä½¿ç”¨å¢å¼ºçš„ JSON æå–å™¨
                parsed_response = extract_json(raw_response)
                
                if parsed_response:
                    reply = parsed_response.get("reply", raw_response)
                    inner_voice = parsed_response.get("inner_voice", "")
                    emotion = parsed_response.get("emotion", "neutral")
                else:
                    raise ValueError("No valid JSON found")
                    
            except Exception as e:
                # å¦‚æœè§£æå¤±è´¥ï¼Œå¯èƒ½ LLM å¹¶æ²¡æœ‰è¿”å› JSONï¼Œè€Œæ˜¯ç›´æ¥è¿”å›äº†æ–‡æœ¬
                # è¿™åœ¨å·¥å…·è°ƒç”¨åå°¤å…¶å¸¸è§ï¼Œè™½ç„¶ Prompt è¦æ±‚ JSONï¼Œä½† LLM å¯èƒ½â€œå¿˜â€äº†
                # æˆ‘ä»¬åšä¸ªå…¼å®¹ï¼šç›´æ¥æŠŠ raw_response å½“ä½œ reply
                logger.warning(f"[{self.name}] JSONè§£æå¤±è´¥ (ä½¿ç”¨åŸå§‹æ–‡æœ¬): {e}")
                reply = raw_response
                inner_voice = "ç›´æ¥è¾“å‡º"
                emotion = "neutral"

        # å°†æ–°çš„ä¸€è½®å¯¹è¯å­˜å…¥ ShortTerm Memory
        self.memory.add_short_term("user", user_input)
        self.memory.add_short_term("assistant", reply)
        
        # å‘å¸ƒ DriverResponse äº‹ä»¶åˆ°æ€»çº¿ (åŒ…å« Meta æ•°æ®)
        event_bus.publish(Event(
            type="driver_response",
            source="driver",
            payload={"content": reply},
            meta={
                "inner_voice": inner_voice,
                "user_emotion_detect": emotion,
                "psyche_state": str(psyche_state) if psyche_state else "unknown",
                "suggestion_ref": suggestion
            }
        ))
        
        return reply

    def act(self, action):
        """
        æ‰§è¡Œå…·ä½“è¡ŒåŠ¨ã€‚
        """
        print(f"[{self.name}] æ‰§è¡Œè¡ŒåŠ¨: {action}")
