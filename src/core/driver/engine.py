import json
import threading
import time
from datetime import datetime
from typing import Optional, Dict, Any, List

from src.utils.llm_client import LLMClient
from src.utils.logger import logger
from src.utils.json_parser import extract_json
from src.memory.memory_core import Memory
from src.core.bus.event_bus import event_bus
from src.schemas.events import BaseEvent as Event, DriverResponsePayload, UserInputPayload
from src.core.managers.library_manager import library_manager
from src.psyche import psyche_engine, mind_link
from src.config.prompts.prompts import DRIVER_SYSTEM_PROMPT, PROACTIVE_DRIVER_PROMPT
from src.config.settings.settings import settings
from src.tools.registry import tool_registry

class Driver:
    """
    Fè„‘ (Fast Brain) / å¿«è„‘
    è´Ÿè´£ï¼šå®æ—¶äº¤äº’ã€çŸ­æœŸå†³ç­–ã€å…·ä½“è¡ŒåŠ¨ã€‚
    ç‰¹ç‚¹ï¼šååº”å¿«ï¼Œç›´æ¥æ§åˆ¶è¾“å‡ºï¼Œå— Psyche (å¿ƒæ™º) å½±å“ã€‚
    æ¨¡å‹ï¼šQwen (é€šä¹‰åƒé—®)
    """
    def __init__(self, name="Driver", memory=None):
        self.name = name
        # Fè„‘ä½¿ç”¨ Qwen
        self.llm = LLMClient(provider="qwen")
        self.llm.model = settings.F_BRAIN_MODEL
        self.memory = memory if memory else Memory()
        
        # è®¢é˜…äº‹ä»¶æ€»çº¿
        event_bus.subscribe(self._on_event)
        self._thinking_lock = threading.Lock() # é˜²æ­¢æ€è€ƒå†²çª
        self.last_interaction_time = 0 # ä¸Šæ¬¡äº’åŠ¨æ—¶é—´ (Unix Timestamp)
        
        logger.info(f"[{self.name}] åˆå§‹åŒ–å®Œæˆã€‚æ¨¡å‹: {self.llm.model}ã€‚")

    def _on_event(self, event):
        """äº‹ä»¶ç›‘å¬"""
        if event.type == "proactive_instruction":
            # ä½¿ç”¨ç»Ÿä¸€æ¥å£è·å– content
            instruction = event.get_content()
            if instruction:
                # åœ¨æ–°çº¿ç¨‹ä¸­æ‰§è¡Œï¼Œé¿å…é˜»å¡äº‹ä»¶æ€»çº¿åˆ†å‘
                threading.Thread(target=self.proactive_speak, args=(instruction,), daemon=True).start()

    def _get_dynamic_cooldown(self) -> float:
        """æ ¹æ®æ—¶é—´ä¸å¿ƒæ™ºçŠ¶æ€åŠ¨æ€è®¡ç®—ä¸»åŠ¨å‘è¨€å†·å´æ—¶é—´"""
        base = float(settings.PROACTIVE_COOLDOWN)
        hour = datetime.now().hour

        # æ·±å¤œé™ä½æ‰“æ‰° (23:00-07:00)
        if hour >= 23 or hour < 7:
            base *= 2

        # laziness é«˜æ—¶æ›´ä¸ä¸»åŠ¨
        try:
            laziness = psyche_engine.get_raw_state()["dimensions"]["laziness"]["value"]
            base *= (1 + float(laziness))
        except Exception:
            pass

        return base

    def proactive_speak(self, instruction):
        """
        [New] ä¸»åŠ¨å‘èµ·å¯¹è¯ (åŸºäº Sè„‘ æŒ‡ä»¤)
        """
        # 1. åŠ¨æ€å†·å´æ£€æŸ¥
        dynamic_cooldown = self._get_dynamic_cooldown()
        if time.time() - self.last_interaction_time < dynamic_cooldown:
            # å®‰å…¨æ‰“å° instruction
            instr_str = str(instruction)
            logger.info(f"[{self.name}] å¤„äºå†·å´æœŸ({dynamic_cooldown:.1f}s)ï¼Œè·³è¿‡ä¸»åŠ¨å‘è¨€æŒ‡ä»¤: {instr_str[:50]}...")
            return

        # å¦‚æœæ­£åœ¨æ€è€ƒï¼ˆå¤„ç†ç”¨æˆ·è¾“å…¥ï¼‰ï¼Œåˆ™å¿½ç•¥è¿™æ¬¡ä¸»åŠ¨å°è¯•
        if not self._thinking_lock.acquire(blocking=False):
            logger.info(f"[{self.name}] æ­£åœ¨å¿™äºå›å¤ç”¨æˆ·ï¼Œå¿½ç•¥ä¸»åŠ¨å¹²é¢„æŒ‡ä»¤: {instruction}")
            return
            
        try:
            logger.info(f"[{self.name}] âš¡ æ”¶åˆ°æ½œæ„è¯†å†²åŠ¨: {instruction}")
            
            # [Fix] ç¡®ä¿ instruction æ˜¯å­—ç¬¦ä¸²ï¼Œå¦‚æœæ˜¯å­—å…¸åˆ™è½¬ä¸º JSON å­—ç¬¦ä¸²
            instruction_str = json.dumps(instruction, ensure_ascii=False) if isinstance(instruction, (dict, list)) else str(instruction)
            
            current_psyche = psyche_engine.get_state_summary()
            # ä½¿ç”¨è½¬æ¢åçš„å­—ç¬¦ä¸²è¿›è¡Œæ£€ç´¢
            long_term_context = self.memory.get_relevant_long_term(query=instruction_str, limit=settings.DEFAULT_LONG_TERM_LIMIT)
            current_time = datetime.now().strftime("%Y-%m-%d %H:%M:%S")

            system_prompt = PROACTIVE_DRIVER_PROMPT.format(
                current_time=current_time,
                psyche_desc=current_psyche,
                instruction=instruction_str, # ä½¿ç”¨å­—ç¬¦ä¸²æ ¼å¼
                long_term_context=long_term_context
            )

            # è°ƒç”¨ LLM ç”Ÿæˆä¸»åŠ¨è¯è¯­
            # æ³¨æ„ï¼šè¿™é‡Œä¸éœ€è¦ toolsï¼Œå› ä¸ºåªæ˜¯å•çº¯çš„å¼€å¯è¯é¢˜
            response = self.llm.chat([{"role": "system", "content": system_prompt}])
            
            if not response:
                return

            # è§£æå›å¤
            reply, inner_voice, emotion = self._parse_proactive_response(response)

            if reply:
                # è¾“å‡ºç»“æœ
                # æ³¨æ„ï¼šåœ¨ CLI æ¨¡å¼ä¸‹ï¼Œè¿™å¯èƒ½ä¼šæ‰“æ–­ç”¨æˆ·çš„è¾“å…¥è¡Œï¼Œè¿™æ˜¯å·²çŸ¥é™åˆ¶
                logger.info(f"[{self.name}] (ä¸»åŠ¨): {reply}")
                
                # å­˜å…¥çŸ­æœŸè®°å¿†
                self.memory.add_short_term("assistant", reply)
                
                # å‘å¸ƒäº‹ä»¶
                event_bus.publish(Event(
                    type="driver_response",
                    source="driver",
                    payload=DriverResponsePayload(content=reply),
                    meta={
                        "inner_voice": inner_voice,
                        "user_emotion_detect": emotion,
                        "proactive": True
                    }
                ))
        except Exception as e:
            logger.error(f"[{self.name}] ä¸»åŠ¨å‘è¨€å¤±è´¥: {e}", exc_info=True)
        finally:
            self._thinking_lock.release()

    def _parse_proactive_response(self, response: str):
        """è§£æä¸»åŠ¨å‘è¨€çš„ LLM å“åº”"""
        try:
            parsed = extract_json(response)
            if parsed:
                return (
                    parsed.get("reply", response),
                    parsed.get("inner_voice", "æˆ‘æƒ³è¯´è¯..."),
                    parsed.get("emotion", "curious")
                )
        except json.JSONDecodeError as e:
            logger.warning(f"[{self.name}] JSON Parsing Failed: {e}. Raw: {response}")
        
        # é™çº§å¤„ç†
        return response, "", "neutral"

    def think(self, user_input: str, psyche_state: Optional[Dict[str, Any]] = None) -> str:
        """
        ä¸»æ€è€ƒå…¥å£
        :param user_input: ç”¨æˆ·è¾“å…¥
        :param psyche_state: (å¯é€‰) å¤–éƒ¨ä¼ å…¥çš„å¿ƒæ™ºçŠ¶æ€å¿«ç…§
        :return: å›å¤å†…å®¹
        """
        if not user_input:
            return ""

        # è·å–é”ï¼Œæ ‡å¿—æ­£åœ¨æ€è€ƒ
        # æ³¨æ„ï¼šè¿™ä¼šé˜»å¡ç›´åˆ°è·å¾—é”ï¼Œç¡®ä¿ä¸ä¼šä¸ proactive_speak å†²çª
        with self._thinking_lock:
            response = self._think_internal(user_input, psyche_state)
            
            # æ›´æ–°æœ€åäº’åŠ¨æ—¶é—´
            self.last_interaction_time = time.time()
            
            return response

    def _think_internal(self, user_input, psyche_state=None, suggestion=""):
        """é‡æ„åçš„å†…éƒ¨æ€è€ƒæµç¨‹"""
        # 1. æ·±åº¦ç»´æŠ¤æ£€æŸ¥ (ä¿æŒåŸæœ‰çš„æ‰‹åŠ¨è§¦å‘é€»è¾‘)
        if "æ·±åº¦ç»´æŠ¤" in user_input or "/deep_clean" in user_input:
            return self._handle_deep_clean(user_input)

        # 2. å‡†å¤‡ä¸Šä¸‹æ–‡
        context = self._prepare_context(user_input)
        
        # 3. ç»„è£…æ¶ˆæ¯
        messages = self._build_messages(user_input, context)
        
        # 4. å‘å¸ƒ UserInput äº‹ä»¶
        event_bus.publish(Event(
            type="user_input",
            source="user",
            payload=UserInputPayload(content=user_input),
            meta={}
        ))

        # 5. è°ƒç”¨ LLM (å«å·¥å…·å¾ªç¯)
        tools = tool_registry.get_openai_tools()
        raw_response = self._call_llm_with_tools(messages, tools)

        # 6. è§£æå“åº”
        reply, inner_voice, emotion = self._parse_driver_response(raw_response)

        # 7. æ”¶å°¾ï¼šå­˜å‚¨è®°å¿†å¹¶å‘å¸ƒå“åº”äº‹ä»¶
        self._finalize_interaction(user_input, reply, inner_voice, emotion, psyche_state, suggestion)
        
        return reply

    def _prepare_context(self, user_input: str) -> Dict[str, Any]:
        """å‡†å¤‡æ€è€ƒæ‰€éœ€çš„å…¨éƒ¨ä¸Šä¸‹æ–‡ä¿¡æ¯"""
        # A. æ›´æ–°/è¯»å–å¿ƒæ™º
        # äº²å¯†åº¦å˜åŒ–ä¸åœ¨ F è„‘ç¡¬ç¼–ç ï¼Œäº¤ç”± S è„‘/psyche_delta é©±åŠ¨
        current_psyche = psyche_engine.get_state_summary()
        
        # B. è¯»å–æ½œæ„è¯†ç›´è§‰
        intuition = mind_link.read_intuition()
        if intuition:
            logger.info(f"[{self.name}] ğŸ§  æ„ŸçŸ¥åˆ°æ½œæ„è¯†ç›´è§‰: {intuition[:30]}...")
            
        # C. è®°å¿†æ£€ç´¢ (å«åˆ«åè§£æä¸ç”»åƒ)
        long_term_context = self.memory.get_relevant_long_term(query=user_input)
        
        # åˆ«åè§£æ
        try:
            alias_match = self.memory.search_alias(query=user_input, threshold=0.4)
            if alias_match:
                alias, target, dist = alias_match
                logger.info(f"[{self.name}] ğŸ” æ£€æµ‹åˆ°æ¨¡ç³Šåˆ«å: '{alias}' -> '{target}' (dist: {dist:.4f})")
                alias_context = f"\n[System Note]: ç”¨æˆ·å½“å‰æåˆ°çš„ '{alias}' åœ¨ç³»ç»Ÿä¸­è¢«è¯†åˆ«ä¸º '{target}'ã€‚\n"
                if target in ["User", "ç”¨æˆ·"]:
                    alias_context += "(å·²è‡ªåŠ¨å…³è”ç”¨æˆ·ç”»åƒ)\n"
                long_term_context = alias_context + long_term_context
        except Exception as e:
            logger.warning(f"[{self.name}] åˆ«åæ£€ç´¢å¼‚å¸¸: {e}")

        # ç”»åƒæ£€ç´¢
        try:
            user_profile = self._get_user_profile_string()
            if user_profile:
                long_term_context = user_profile + "\n" + long_term_context
        except Exception as e:
            logger.warning(f"[{self.name}] å›¾è°±ç”»åƒæ£€ç´¢å¤±è´¥: {e}")

        # D. æŠ€èƒ½ä¸å·¥å…·åˆ—è¡¨
        relevant_skills = library_manager.search_skills(user_input, top_k=2)
        skill_info = ""
        if relevant_skills:
            skill_info = "ã€ç›¸å…³æŠ€èƒ½æ¨èã€‘:\n" + "".join([f"- {s['name']} (ID: {s['id']}): {s['description']}\n" for s in relevant_skills])
            skill_info += "(å¦‚æœéœ€è¦ä½¿ç”¨ï¼Œè¯·è°ƒç”¨ `read_skill` è·å–è¯¦ç»†æŒ‡å—ï¼Œæˆ–ç›´æ¥å°è¯• `run_shell_command` å¦‚æœä½ çŸ¥é“æ€ä¹ˆç”¨)"

        all_tools = tool_registry.get_tools()
        tool_list_str = "".join([f"- {t.name}: {t.description}\n" for t in all_tools])

        return {
            "current_time": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "psyche_desc": current_psyche,
            "suggestion": intuition,
            "long_term_context": long_term_context,
            "skill_info": skill_info,
            "tool_list": tool_list_str
        }

    def _get_user_profile_string(self) -> str:
        """ä»å›¾è°±ä¸­æå–ç”¨æˆ·ç”»åƒå­—ç¬¦ä¸²"""
        user_profile = []
        for name in ["User", "ç”¨æˆ·"]:
            user_profile.extend(self.memory.graph_storage.get_cognitive_subgraph(name, relation_type="attribute"))
            user_profile.extend(self.memory.graph_storage.get_cognitive_subgraph(name, relation_type="social"))
        
        if not user_profile:
            return ""

        profile_str = "\nã€å½“å‰ç”¨æˆ·ç”»åƒ (Active Profile)ã€‘:\n"
        seen_relations = set()
        for p in user_profile:
            rel_key = f"{p['source']}-{p['relation']}-{p['target']}"
            if rel_key in seen_relations: continue
            seen_relations.add(rel_key)
            
            if p['relation'] in ["has_name", "called", "name_is", "åå­—æ˜¯"]:
                profile_str += f"- åå­—: {p['target']}\n"
            else:
                profile_str += f"- {p['relation']}: {p['target']}"
                if p.get('meta', {}).get('emotion_tag'):
                    profile_str += f" (Emotion: {p['meta']['emotion_tag']})"
                profile_str += "\n"
        return profile_str

    def _build_messages(self, user_input: str, context: Dict[str, Any]) -> List[Dict[str, str]]:
        """ç»„è£… LLM è¯·æ±‚æ¶ˆæ¯åˆ—è¡¨"""
        system_prompt = DRIVER_SYSTEM_PROMPT.format(**context)
        messages = [{"role": "system", "content": system_prompt}]
        messages.extend(self.memory.get_recent_history(limit=15))
        messages.append({"role": "user", "content": user_input})
        return messages

    def _call_llm_with_tools(self, messages: List[Dict[str, str]], tools: List[Dict[str, Any]]) -> Optional[str]:
        """æ‰§è¡Œ LLM è°ƒç”¨å¾ªç¯ï¼Œå¤„ç†å·¥å…·è°ƒç”¨"""
        raw_response = None
        for _ in range(3): # æœ€å¤š 3 è½®å¾ªç¯
            response = self.llm.chat(messages, tools=tools)
            if not response: break
            
            if isinstance(response, str):
                raw_response = response
                break
                
            if hasattr(response, 'tool_calls') and response.tool_calls:
                # è®°å½• Assistant çš„å·¥å…·è°ƒç”¨å›å¤
                if hasattr(response, 'model_dump'):
                    messages.append(response.model_dump())
                else:
                    messages.append(response.to_dict() if hasattr(response, 'to_dict') else response)
                
                for tool_call in response.tool_calls:
                    res = self._execute_tool(tool_call)
                    messages.append({
                        "role": "tool",
                        "tool_call_id": tool_call.id,
                        "name": tool_call.function.name,
                        "content": str(res)
                    })
                continue # ç»§ç»­ä¸‹ä¸€è½®è®© LLM æ€»ç»“ç»“æœ
            else:
                raw_response = getattr(response, 'content', None)
                break
        return raw_response

    def _execute_tool(self, tool_call) -> str:
        """æ‰§è¡Œå•ä¸ªå·¥å…·è°ƒç”¨"""
        name = tool_call.function.name
        args_str = tool_call.function.arguments
        logger.info(f"[{self.name}] ğŸ› ï¸ æ­£åœ¨è°ƒç”¨å·¥å…·: {name} Args: {args_str}")
        try:
            args = json.loads(args_str)
            result = tool_registry.execute(name, **args)
            display_result = str(result)[:100] + "..." if len(str(result)) > 100 else str(result)
            logger.info(f"[{self.name}] ğŸ› ï¸ å·¥å…·æ‰§è¡Œç»“æœ: {display_result}")
            return result
        except Exception as e:
            logger.error(f"[{self.name}] ğŸ› ï¸ å·¥å…·æ‰§è¡Œå‡ºé”™: {e}")
            return f"Error: {str(e)}"

    def _parse_driver_response(self, raw_response: Optional[str]):
        """è§£æ LLM åŸå§‹å“åº”ä¸º (reply, inner_voice, emotion)"""
        if raw_response is None:
            return "æŠ±æ­‰ï¼Œæˆ‘ç°åœ¨çš„æ€ç»ªæœ‰ç‚¹ä¹±ï¼ˆè¿æ¥é”™è¯¯ï¼‰ï¼Œè¯·ç¨åå†è¯•ã€‚", "ç³»ç»Ÿé”™è¯¯", "error"

        try:
            parsed = extract_json(raw_response)
            if parsed:
                return (
                    parsed.get("reply", raw_response),
                    parsed.get("inner_voice", ""),
                    parsed.get("emotion", "neutral")
                )
        except Exception as e:
            logger.warning(f"[{self.name}] JSONè§£æå¤±è´¥ (ä½¿ç”¨åŸå§‹æ–‡æœ¬): {e}")
            
        return raw_response, "ç›´æ¥è¾“å‡º", "neutral"

    def _finalize_interaction(self, user_input, reply, inner_voice, emotion, psyche_state, suggestion):
        """ä¿å­˜è®°å¿†å¹¶å‘å¸ƒæœ€ç»ˆäº‹ä»¶"""
        self.memory.add_short_term("user", user_input)
        self.memory.add_short_term("assistant", reply)
        
        event_bus.publish(Event(
            type="driver_response",
            source="driver",
            payload=DriverResponsePayload(content=reply),
            meta={
                "inner_voice": inner_voice,
                "user_emotion_detect": emotion,
                "psyche_state": str(psyche_state) if psyche_state else "unknown",
                "suggestion_ref": suggestion
            }
        ))

    def _handle_deep_clean(self, user_input: str) -> str:
        """å¤„ç†æ·±åº¦ç»´æŠ¤æŒ‡ä»¤"""
        logger.info(f"[{self.name}] æ”¶åˆ°æ·±åº¦ç»´æŠ¤æŒ‡ä»¤ï¼Œæ­£åœ¨è½¬å‘ç»™ S è„‘...")
        reply = "å¥½çš„ï¼Œæ­£åœ¨å¯åŠ¨æ·±åº¦ç»´æŠ¤ç¨‹åºã€‚è¿™å¯èƒ½éœ€è¦å‡ åˆ†é’Ÿæ—¶é—´ï¼Œè¯·ç¨å€™..."
        if hasattr(self.memory, 'navigator') and self.memory.navigator:
            threading.Thread(target=self.memory.navigator.deep_clean_manager.perform_deep_clean, args=("manual",), daemon=True).start()
        
        self.memory.add_short_term("user", user_input)
        self.memory.add_short_term("assistant", reply)
        event_bus.publish(Event(
            type="driver_response",
            source="driver",
            payload=DriverResponsePayload(content=reply),
            meta={"inner_voice": "ç³»ç»Ÿç»´æŠ¤"}
        ))
        return reply

    def act(self, action):
        """æ‰§è¡Œå…·ä½“è¡ŒåŠ¨ã€‚[Deprecated: è¡ŒåŠ¨å·²é€šè¿‡å·¥å…·ç³»ç»Ÿæ‰§è¡Œ]"""
        logger.warning(f"[{self.name}] act() å·²åºŸå¼ƒï¼Œè¯·ä½¿ç”¨å·¥å…·ç³»ç»Ÿã€‚Action: {action}")